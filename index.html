<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="简体中文">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="张奇怪的blog">
<meta property="og:url" content="https://zhanghongtong.github.io/index.html">
<meta property="og:site_name" content="张奇怪的blog">
<meta property="og:locale" content="简体中文">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="张奇怪的blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhanghongtong.github.io/"/>





  <title>张奇怪的blog</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="简体中文">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">张奇怪的blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/30/Kunbernetes安装部署工具Helm，使用helm管理与发布kubernetes应用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/30/Kunbernetes安装部署工具Helm，使用helm管理与发布kubernetes应用/" itemprop="url">Kunbernetes安装部署工具Helm，使用helm管理与发布kubernetes应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-30T15:32:30+08:00">
                2018-10-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Helm介绍"><a href="#Helm介绍" class="headerlink" title="Helm介绍"></a>Helm介绍</h1><p>Helm是管理Kubernetes包的工具，Helm能提供下面的能力：</p>
<ul>
<li>创建新的charts</li>
<li>将charts打包成tgz文件</li>
<li>与chart仓库交互</li>
<li>安装和卸载Kubernetes的应用</li>
<li>管理使用Helm安装的charts的生命周期</li>
</ul>
<p>在Helm中，有三个需要了解的重要概念：</p>
<ul>
<li>chart：是创建Kubernetes应用实例的信息集合；</li>
<li>config：创建发布对象的chart的配置信息</li>
<li>release：chart的运行实例，包含特定的config</li>
</ul>
<h2 id="Helm组件"><a href="#Helm组件" class="headerlink" title="Helm组件"></a>Helm组件</h2><p>在Helm中有两个主要的组件，既Helm客户端和Tiller服务器：</p>
<p><strong>Helm客户端</strong>：这是一个供终端用户使用的命令行工具，客户端负责如下的工作：</p>
<ul>
<li>本地chart开发</li>
<li>管理仓库</li>
<li>与Tiller服务器交互<ul>
<li>发送需要被安装的charts</li>
<li>请求关于发布版本的信息</li>
<li>请求更新或者卸载已安装的发布版本</li>
</ul>
</li>
</ul>
<p><strong>Tiller服务器</strong>： Tiller服务部署在Kubernetes集群中，Helm客户端通过与Tiller服务器进行交互，并最终与Kubernetes API服务器进行交互。 Tiller服务器负责如下的工作：</p>
<ul>
<li>监听来自于Helm客户端的请求</li>
<li>组合chart和配置来构建一个发布</li>
<li>在Kubernetes中安装，并跟踪后续的发布</li>
<li>通过与Kubernetes交互，更新或者chart</li>
</ul>
<p>客户端负责管理chart，服务器发展管理发布。 </p>
<h2 id="Helm技术实现"><a href="#Helm技术实现" class="headerlink" title="Helm技术实现"></a>Helm技术实现</h2><p>Helm客户端是使用Go语言编写的，它通过gRPC协议与Tiller服务器交互。</p>
<p>Tiller服务器也是使用Go语言编写的，它使用Kubernetes客户端类库（当前是哦那个REST+JSON）与Kubernetes进行通讯。</p>
<p>Tiller服务器通过Kubernetes的ConfigMap存储信息，因此本身没有用于存储数据库。</p>
<h1 id="Helm安装部署"><a href="#Helm安装部署" class="headerlink" title="Helm安装部署"></a>Helm安装部署</h1><h2 id="安装Helm客户端"><a href="#安装Helm客户端" class="headerlink" title="安装Helm客户端"></a>安装Helm客户端</h2><p>在进行Helm客户端安装前，请确认已有可用的Kubernetes集群环境，并已安装了kubectl。</p>
<p>通过访问：<a href="https://github.com/kubernetes/helm/releases。" target="_blank" rel="noopener">https://github.com/kubernetes/helm/releases。</a><br>下载Helm的合适的版本。</p>
<ol>
<li>此文下载helm-v2.8.0-linux-amd64.tgz版本；</li>
<li>解压缩文件：tar -zxvf helm-v2.8.0-linux-amd64.tgz</li>
<li>将解压缩后的helm移至/usr/local/bin目录下：mv linux-amd64/helm /usr/local/bin/helm</li>
</ol>
<p><strong>注意</strong>：</p>
<ul>
<li>最好在安装kubectl命令行工具的机器上安装Helm客户端；或者将安装kubectl命令行工具生成的配置文件（$HOME/.kube/config）复制到Helm客户端所安装的机器上($HOME/.kube/config)。</li>
</ul>
<h2 id="安装Tiller服务器"><a href="#安装Tiller服务器" class="headerlink" title="安装Tiller服务器"></a>安装Tiller服务器</h2><h3 id="使用Service-Account安装"><a href="#使用Service-Account安装" class="headerlink" title="使用Service Account安装"></a>使用Service Account安装</h3><ol>
<li><p>创建一个名为tiller的Service Account</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create serviceaccount tiller --namespace kube-system</span><br></pre></td></tr></table></figure>
</li>
<li><p>授予名为tiller的Service Account集群管理员角色cluster-admin:</p>
<ul>
<li><p>将tiller绑定至集群管理员角色的的yaml文件如下所示：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$vim rbac-config.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1 </span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">name: tiller </span><br><span class="line">roleRef: </span><br><span class="line">apiGroup: rbac.authorization.k8s.io </span><br><span class="line">kind: ClusterRole </span><br><span class="line">name: cluster-admin </span><br><span class="line">subjects: </span><br><span class="line">- kind: ServiceAccount </span><br><span class="line">name: tiller </span><br><span class="line">namespace: kube-system</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过执行kubectl create -f将授予tiller集群管理员角色：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f rbac-config.yaml</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>安装Tiller服务器</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm init --service-account tiller</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h3><p>在安装完成后，可以通过执行如下命令来检查是安装成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm version</span><br></pre></td></tr></table></figure></p>
<p>如果正确显示Helm客户端和Tiller服务器的版本，这表示安装成功。</p>
<p>或者通过执行kubectl的如下命令来查看是否已正常按照Tiller服务器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure></p>
<h1 id="Helm使用"><a href="#Helm使用" class="headerlink" title="Helm使用"></a>Helm使用</h1><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="查看源"><a href="#查看源" class="headerlink" title="查看源"></a>查看源</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">helm repo list    #列出所有源，当前还没有添加源</span><br><span class="line"># 添加一个国内可以访问的阿里源，不过好像最近不更新了</span><br><span class="line">helm repo add ali https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts  </span><br><span class="line">如果能连外网，可以加google，f8</span><br><span class="line">helm repo add google https://kubernetes-charts.storage.googleapis.com </span><br><span class="line">helm repo add fabric8 https://fabric8.io/helm</span><br><span class="line"># 更新源</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>
<h3 id="查看chart"><a href="#查看chart" class="headerlink" title="查看chart"></a>查看chart</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 查看chart，即已经通过helm部署到 k8s 平台的应用</span><br><span class="line">helm list    或者  helm ls</span><br><span class="line"></span><br><span class="line"># 若要查看或搜索存储库中的 Helm charts，键入以下任一命令</span><br><span class="line">helm search </span><br><span class="line">helm search 存储库名称 #如 stable 或 incubator</span><br><span class="line">helm search chart名称 #如 wordpress 或 spark</span><br><span class="line"></span><br><span class="line"># 查看charm详情</span><br><span class="line">helm inspect ali/wordpress</span><br></pre></td></tr></table></figure>
<h3 id="下载chart"><a href="#下载chart" class="headerlink" title="下载chart"></a>下载chart</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">helm fetch ali/wordpress</span><br><span class="line">[ubuntu@master1 ~]# ls wordpress-0.8.8.tgz </span><br><span class="line">wordpress-0.8.8.tgz</span><br></pre></td></tr></table></figure>
<h3 id="部署应用-wordpress，-通过ali源文件"><a href="#部署应用-wordpress，-通过ali源文件" class="headerlink" title="部署应用 wordpress， 通过ali源文件"></a>部署应用 wordpress， 通过ali源文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --name wordpress-test --set &quot;persistence.enabled=false,mariadb.persistence.enabled=false&quot; ali/wordpress</span><br><span class="line"></span><br><span class="line">[ubuntu@master1 ~]# kubectl get pod </span><br><span class="line">NAME                                        READY     STATUS    RESTARTS   AGE</span><br><span class="line">wordpress-test-mariadb-84b866bf95-7bx5w     1/1       Running   1          4h</span><br><span class="line">wordpress-test-wordpress-5ff8c64b6c-hrh9q   1/1       Running   0          4h</span><br><span class="line">[ubuntu@master1 ~]# kubectl get svc </span><br><span class="line">NAME                       TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">kubernetes                 ClusterIP      10.96.0.1        &lt;none&gt;        443/TCP                      2d</span><br><span class="line">wordpress-test-mariadb     ClusterIP      10.105.71.95     &lt;none&gt;        3306/TCP                     4h</span><br><span class="line">wordpress-test-wordpress   LoadBalancer   10.104.106.150   &lt;pending&gt;     80:30655/TCP,443:32121/TCP   4h</span><br></pre></td></tr></table></figure>
<h3 id="访问wordpress，使用node节点ip-nodeport，-192-168-1-181-30655"><a href="#访问wordpress，使用node节点ip-nodeport，-192-168-1-181-30655" class="headerlink" title="访问wordpress，使用node节点ip + nodeport， 192.168.1.181:30655"></a>访问wordpress，使用node节点ip + nodeport， 192.168.1.181:30655</h3><h3 id="删除应用"><a href="#删除应用" class="headerlink" title="删除应用"></a>删除应用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ubuntu@master1 ~]# helm list</span><br><span class="line">NAME            REVISION    UPDATED                     STATUS      CHART           NAMESPACE</span><br><span class="line">wordpress-test  1           Thu May 17 11:35:07 2018    DEPLOYED    wordpress-0.8.8 default  </span><br><span class="line">[ubuntu@master1 ~]# helm delete wordpress-test</span><br><span class="line">release &quot;wordpress-test&quot; deleted</span><br></pre></td></tr></table></figure>
<h1 id="建立自己的chart"><a href="#建立自己的chart" class="headerlink" title="建立自己的chart"></a>建立自己的chart</h1><p>创建一个自己的chart，看下文档结构，学习下如何使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ helm create emqx</span><br><span class="line">Creating emqx</span><br><span class="line">$ tree misa86</span><br><span class="line">emqx</span><br><span class="line">├── charts     #Chart本身的版本和配置信息</span><br><span class="line">├── Chart.yaml    #Chart本身的版本和配置信息</span><br><span class="line">├── templates    #配置模板目录</span><br><span class="line">│   ├── deployment.yaml    #kubernetes Deployment object</span><br><span class="line">│   ├── _helpers.tpl    #用于修改kubernetes objcet配置的模板</span><br><span class="line">│   ├── ingress.yaml    #kubernetes Deployment object</span><br><span class="line">│   ├── NOTES.txt    #helm提示信息</span><br><span class="line">│   └── service.yaml    #kubernetes Serivce</span><br><span class="line">└── values.yaml    #kubernetes object configuration，定义变量</span><br></pre></td></tr></table></figure></p>
<h2 id="模板-template"><a href="#模板-template" class="headerlink" title="模板 template"></a>模板 template</h2><p>template下包含应用所有的yaml文件模板，应用资源的类型不仅限于deployment 和service这些，k8s支持的都可以<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">$cat templates/deployment.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: apps/v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: &#123;&#123; include &quot;emqx.fullname&quot; . &#125;&#125;</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: &#123;&#123; include &quot;emqx.name&quot; . &#125;&#125;</span><br><span class="line">    helm.sh/chart: &#123;&#123; include &quot;emqx.chart&quot; . &#125;&#125;</span><br><span class="line">    app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125;</span><br><span class="line">    app.kubernetes.io/managed-by: &#123;&#123; .Release.Service &#125;&#125;</span><br><span class="line">spec:</span><br><span class="line">  replicas: &#123;&#123; .Values.replicaCount &#125;&#125;</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: &#123;&#123; include &quot;emqx.name&quot; . &#125;&#125;</span><br><span class="line">      app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: &#123;&#123; include &quot;emqx.name&quot; . &#125;&#125;</span><br><span class="line">        app.kubernetes.io/instance: &#123;&#123; .Release.Name &#125;&#125;</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: &#123;&#123; .Chart.Name &#125;&#125;</span><br><span class="line">          image: &quot;&#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125;&quot;</span><br><span class="line">          imagePullPolicy: &#123;&#123; .Values.image.pullPolicy &#125;&#125;</span><br><span class="line">          ports:</span><br><span class="line">          - containerPort: 1883</span><br><span class="line">          - containerPort: 8883</span><br><span class="line">          - containerPort: 8080</span><br><span class="line">          - containerPort: 18083</span><br><span class="line">          - containerPort: 4369</span><br><span class="line">          - containerPort: 4370</span><br><span class="line">          - containerPort: 6369</span><br><span class="line">          - containerPort: 6370</span><br><span class="line">          - containerPort: 6371</span><br><span class="line">          - containerPort: 6372</span><br><span class="line">          - containerPort: 6373</span><br><span class="line">          - containerPort: 6374</span><br><span class="line">          - containerPort: 6375</span><br><span class="line">          - containerPort: 6376</span><br><span class="line">          - containerPort: 6377</span><br><span class="line">          - containerPort: 6378</span><br><span class="line">          env:</span><br><span class="line">          - name: EMQX_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          - name: EMQX_CLUSTER__DISCOVERY</span><br><span class="line">            value: k8s</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__SERVICE_NAME</span><br><span class="line">            value: &#123;&#123; include &quot;emqx.fullname&quot; . &#125;&#125;</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APISERVER</span><br><span class="line">            value: &#123;&#123; .Values.env.kubeApiserver &#125;&#125;</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__NAMESPACE</span><br><span class="line">            value: &#123;&#123; .Values.env.kubeNamespace &#125;&#125;</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__ADDRESS_TYPE</span><br><span class="line">            value: &#123;&#123; .Values.env.kubeAddressType &#125;&#125;</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          tty: true</span><br></pre></td></tr></table></figure></p>
<p>这是该应用的Deployment的yaml配置文件，其中的双大括号包扩起来的部分是Go template， template “emqx.name” 这类是在 _helpers.tpl 文件中定义的，如果不定义，将来文件名会是随意字符加chart名字。</p>
<p>其中的Values是在values.yaml文件中定义的，应用主要的参数在这边：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ cat values.yaml</span><br><span class="line"># Default values for emqx.</span><br><span class="line"># This is a YAML-formatted file.</span><br><span class="line"># Declare variables to be passed into your templates.</span><br><span class="line"></span><br><span class="line">replicaCount: 2</span><br><span class="line"></span><br><span class="line">image:</span><br><span class="line">  repository: emqx/emqx</span><br><span class="line">  tag: latest</span><br><span class="line">  pullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">env:</span><br><span class="line">  kubeApiserver: http://127.0.0.1:8080</span><br><span class="line">  kubeNamespace: default</span><br><span class="line">  kubeAddressType: ip</span><br><span class="line"></span><br><span class="line">service:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  mqttPort: 1883</span><br><span class="line">  mqttsslPort: 8883</span><br><span class="line">  mgmtPort: 8080</span><br><span class="line">  dashboardPort: 18083</span><br><span class="line">  mappingPort: 4369</span><br><span class="line"></span><br><span class="line">ingress:</span><br><span class="line">  enabled: false</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">    # kubernetes.io/ingress.class: nginx</span><br><span class="line">    # kubernetes.io/tls-acme: &quot;true&quot;</span><br><span class="line">  path: /</span><br><span class="line">  hosts:</span><br><span class="line">    - chart-example.local</span><br><span class="line">  tls: []</span><br><span class="line">  #  - secretName: chart-example-tls</span><br><span class="line">  #    hosts:</span><br><span class="line">  #      - chart-example.local</span><br></pre></td></tr></table></figure></p>
<p>比如在Deployment.yaml中定义的容器镜像image:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.Values.image.repository就是emqx/emqx</span><br><span class="line">.Values.image.tag就是latest</span><br></pre></td></tr></table></figure></p>
<p>以上两个变量值是在install chart的时候自动生成的默认值。</p>
<h2 id="检查配置和模板是否有效"><a href="#检查配置和模板是否有效" class="headerlink" title="检查配置和模板是否有效"></a>检查配置和模板是否有效</h2><p>当使用kubernetes部署应用的时候实际上将templates渲染成最终的kubernetes能够识别的yaml格式。</p>
<p>使用<code>helm install --dry-run --debug &lt;chart_dir&gt;</code>命令来验证chart配置。该输出中包含了模板的变量配置与最终渲染的yaml文件。 deployment service的名字前半截由两个随机的单词组成，随机数加chart名。 这名字也可以改成value方式，自己定义<br>如果配置等有问题此处会报错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line">helm install --set env.kubeApiserver=http://172.31.31.241:8080 --dry-run --debug .</span><br><span class="line">[debug] Created tunnel using local port: &apos;43251&apos;</span><br><span class="line"></span><br><span class="line">[debug] SERVER: &quot;127.0.0.1:43251&quot;</span><br><span class="line"></span><br><span class="line">[debug] Original chart version: &quot;&quot;</span><br><span class="line">[debug] CHART PATH: /home/ubuntu/emqx-helm</span><br><span class="line"></span><br><span class="line">NAME:   quelling-toad</span><br><span class="line">REVISION: 1</span><br><span class="line">RELEASED: Tue Oct 30 08:18:09 2018</span><br><span class="line">CHART: emqx-helm-v1.0</span><br><span class="line">USER-SUPPLIED VALUES:</span><br><span class="line">env:</span><br><span class="line">  kubeApiserver: http://172.31.31.241:8080</span><br><span class="line"></span><br><span class="line">COMPUTED VALUES:</span><br><span class="line">env:</span><br><span class="line">  kubeAddressType: ip</span><br><span class="line">  kubeApiserver: http://172.31.31.241:8080</span><br><span class="line">  kubeNamespace: default</span><br><span class="line">image:</span><br><span class="line">  pullPolicy: IfNotPresent</span><br><span class="line">  tag: latest</span><br><span class="line">ingress:</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">  enabled: false</span><br><span class="line">  hosts:</span><br><span class="line">  - chart-example.local</span><br><span class="line">  path: /</span><br><span class="line">  tls: []</span><br><span class="line">replicaCount: 2</span><br><span class="line">service:</span><br><span class="line">  dashboardPort: 18083</span><br><span class="line">  mappingPort: 4369</span><br><span class="line">  mgmtPort: 8080</span><br><span class="line">  mqttPort: 1883</span><br><span class="line">  mqttsslPort: 8883</span><br><span class="line">  type: ClusterIP</span><br><span class="line"></span><br><span class="line">HOOKS:</span><br><span class="line">MANIFEST:</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: emqx-helm/templates/service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: quelling-toad-emqx-helm</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: emqx-helm</span><br><span class="line">    helm.sh/chart: emqx-helm-v1.0</span><br><span class="line">    app.kubernetes.io/instance: quelling-toad</span><br><span class="line">    app.kubernetes.io/managed-by: Tiller</span><br><span class="line">spec:</span><br><span class="line">  type: ClusterIP</span><br><span class="line">  ports:</span><br><span class="line">  - name: mqtt</span><br><span class="line">    port: 1883</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 1883</span><br><span class="line">  - name: mqttssl</span><br><span class="line">    port: 8883</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8883</span><br><span class="line">  - name: mgmt</span><br><span class="line">    port: 8080</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  - name: dashboard</span><br><span class="line">    port: 18083</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 18083</span><br><span class="line">  - name: mapping</span><br><span class="line">    port: 4369</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 4369</span><br><span class="line">  selector:</span><br><span class="line">    app.kubernetes.io/name: emqx-helm</span><br><span class="line">    app.kubernetes.io/instance: quelling-toad</span><br><span class="line">---</span><br><span class="line"># Source: emqx-helm/templates/deployment.yaml</span><br><span class="line">apiVersion: apps/v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: quelling-toad-emqx-helm</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: emqx-helm</span><br><span class="line">    helm.sh/chart: emqx-helm-v1.0</span><br><span class="line">    app.kubernetes.io/instance: quelling-toad</span><br><span class="line">    app.kubernetes.io/managed-by: Tiller</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app.kubernetes.io/name: emqx-helm</span><br><span class="line">      app.kubernetes.io/instance: quelling-toad</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app.kubernetes.io/name: emqx-helm</span><br><span class="line">        app.kubernetes.io/instance: quelling-toad</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: emqx-helm</span><br><span class="line">          image: &quot;emqx/emqx:latest&quot;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">          - containerPort: 1883</span><br><span class="line">          - containerPort: 8883</span><br><span class="line">          - containerPort: 8080</span><br><span class="line">          - containerPort: 18083</span><br><span class="line">          - containerPort: 4369</span><br><span class="line">          - containerPort: 4370</span><br><span class="line">          - containerPort: 6369</span><br><span class="line">          - containerPort: 6370</span><br><span class="line">          - containerPort: 6371</span><br><span class="line">          - containerPort: 6372</span><br><span class="line">          - containerPort: 6373</span><br><span class="line">          - containerPort: 6374</span><br><span class="line">          - containerPort: 6375</span><br><span class="line">          - containerPort: 6376</span><br><span class="line">          - containerPort: 6377</span><br><span class="line">          - containerPort: 6378</span><br><span class="line">          env:</span><br><span class="line">          - name: EMQX_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          - name: EMQX_CLUSTER__DISCOVERY</span><br><span class="line">            value: k8s</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__SERVICE_NAME</span><br><span class="line">            value: quelling-toad-emqx-helm</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APISERVER</span><br><span class="line">            value: http://172.31.31.241:8080</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__NAMESPACE</span><br><span class="line">            value: default</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__ADDRESS_TYPE</span><br><span class="line">            value: ip</span><br><span class="line">          - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">            value: emqx</span><br><span class="line">          tty: true</span><br></pre></td></tr></table></figure></p>
<h2 id="部署到kubernetes"><a href="#部署到kubernetes" class="headerlink" title="部署到kubernetes"></a>部署到kubernetes</h2><p>在emqx目录下执行下面的命令将应用部署到kubernetes集群上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --set env.kubeApiserver=http://172.31.31.241:8080 .</span><br><span class="line">NAME:   ugly-bumblebee</span><br><span class="line">LAST DEPLOYED: Tue Oct 30 08:19:17 2018</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME                      AGE</span><br><span class="line">ugly-bumblebee-emqx-helm  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta2/Deployment</span><br><span class="line">ugly-bumblebee-emqx-helm  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line"></span><br><span class="line">NAME                                       READY  STATUS             RESTARTS  AGE</span><br><span class="line">ugly-bumblebee-emqx-helm-5bc599849f-n4htc  0/1    ContainerCreating  0         0s</span><br><span class="line">ugly-bumblebee-emqx-helm-5bc599849f-xwdn7  0/1    ContainerCreating  0         0s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">1. Get the application URL by running these commands:</span><br><span class="line">  export POD_NAME=$(kubectl get pods --namespace default -l &quot;app.kubernetes.io/name=emqx-helm,app.kubernetes.io/instance=ugly-bumblebee&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class="line">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class="line">  kubectl port-forward $POD_NAME 8080:80</span><br></pre></td></tr></table></figure></p>
<h2 id="查看部署的relaese"><a href="#查看部署的relaese" class="headerlink" title="查看部署的relaese"></a>查看部署的relaese</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ helm list</span><br><span class="line">NAME           	REVISION	UPDATED                 	STATUS  	CHART         	APP VERSION	NAMESPACE</span><br><span class="line">ugly-bumblebee 	1       	Tue Oct 30 08:19:17 2018	DEPLOYED	emqx-helm-v1.0	v1.0       	default</span><br><span class="line"></span><br><span class="line">$ helm delete ugly-bumblebee</span><br><span class="line">release &quot;ugly-bumblebee&quot; deleted</span><br></pre></td></tr></table></figure>
<h2 id="打包分享"><a href="#打包分享" class="headerlink" title="打包分享"></a>打包分享</h2><p>我们可以修改Chart.yaml中的helm chart配置信息，然后使用下列命令将chart打包成一个压缩文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ helm package .</span><br><span class="line">Successfully packaged chart and saved it to: /home/ubuntu/emqx/emqx-v1.0.tgz</span><br></pre></td></tr></table></figure></p>
<h1 id="Chart-Repository"><a href="#Chart-Repository" class="headerlink" title="Chart Repository"></a>Chart Repository</h1><p>chart 库是带有一个 index.yaml 文件和任意个打包 cahrt 的 HTTP 服务器。当准备好分享 chart 时，首选方法是将其上传到 chart 库。</p>
<p>由于 chart 库可以是任何可以提供 YAML 和 tar 文件并可以回答 GET 请求的 HTTP 服务器，因此当托管自己的 chart 库时，很多选择。例如，可以使用 Google 云端存储（GCS）存储桶，Amazon S3 存储桶，Github Pages，甚至可以创建自己的 Web 服务器。</p>
<h2 id="创建-chart-库"><a href="#创建-chart-库" class="headerlink" title="创建 chart 库"></a>创建 chart 库</h2><h3 id="chart-库结构"><a href="#chart-库结构" class="headerlink" title="chart 库结构"></a>chart 库结构</h3><p>chart 库由打包的 chart 和一个名为的特殊文件组成， index.yaml 其中包含 chart 库中所有 chart 的索引。通常，index.yaml 描述的 chart 也是托管在同一台服务器上，源代码文件也是如此。</p>
<p>例如，chart 库的布局 <a href="https://example.com/charts" target="_blank" rel="noopener">https://example.com/charts</a> 可能如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">charts/</span><br><span class="line">  |</span><br><span class="line">  |- index.yaml</span><br><span class="line">  |</span><br><span class="line">  |- alpine-0.1.2.tgz</span><br><span class="line">  |</span><br><span class="line">  |- alpine-0.1.2.tgz.prov</span><br></pre></td></tr></table></figure></p>
<p>这种情况下，索引文件包含有关一个 chart（Alpine chart）的信息，并提供该 chart 的下载 URL <a href="https://example.com/charts/alpine-0.1.2.tgz。" target="_blank" rel="noopener">https://example.com/charts/alpine-0.1.2.tgz。</a></p>
<p>不要求 chart 包与 index.yaml 文件位于同一台服务器上 。但是，发在一起这样做通常是最简单的。</p>
<h3 id="索引文件"><a href="#索引文件" class="headerlink" title="索引文件"></a>索引文件</h3><p>索引文件是一个叫做 yaml 文件 index.yaml。它包含一些关于包的元数据，包括 chart 的 Chart.yaml 文件的内容。一个有效的 chart 库必须有一个索引文件。索引文件包含有关 chart 库中每个 chart 的信息。helm repo index 命令将根据包含打包的 chart 的给定本地目录生成索引文件。</p>
<p>下面一个索引文件的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">entries:</span><br><span class="line">  alpine:</span><br><span class="line">    - created: 2016-10-06T16:23:20.499814565-06:00</span><br><span class="line">      description: Deploy a basic Alpine Linux pod</span><br><span class="line">      digest: 99c76e403d752c84ead610644d4b1c2f2b453a74b921f422b9dcb8a7c8b559cd</span><br><span class="line">      home: https://k8s.io/helm</span><br><span class="line">      name: alpine</span><br><span class="line">      sources:</span><br><span class="line">      - https://github.com/kubernetes/helm</span><br><span class="line">      urls:</span><br><span class="line">      - https://technosophos.github.io/tscharts/alpine-0.2.0.tgz</span><br><span class="line">      version: 0.2.0</span><br><span class="line">    - created: 2016-10-06T16:23:20.499543808-06:00</span><br><span class="line">      description: Deploy a basic Alpine Linux pod</span><br><span class="line">      digest: 515c58e5f79d8b2913a10cb400ebb6fa9c77fe813287afbacf1a0b897cd78727</span><br><span class="line">      home: https://k8s.io/helm</span><br><span class="line">      name: alpine</span><br><span class="line">      sources:</span><br><span class="line">      - https://github.com/kubernetes/helm</span><br><span class="line">      urls:</span><br><span class="line">      - https://technosophos.github.io/tscharts/alpine-0.1.0.tgz</span><br><span class="line">      version: 0.1.0</span><br><span class="line">  nginx:</span><br><span class="line">    - created: 2016-10-06T16:23:20.499543808-06:00</span><br><span class="line">      description: Create a basic nginx HTTP server</span><br><span class="line">      digest: aaff4545f79d8b2913a10cb400ebb6fa9c77fe813287afbacf1a0b897cdffffff</span><br><span class="line">      home: https://k8s.io/helm</span><br><span class="line">      name: nginx</span><br><span class="line">      sources:</span><br><span class="line">      - https://github.com/kubernetes/charts</span><br><span class="line">      urls:</span><br><span class="line">      - https://technosophos.github.io/tscharts/nginx-1.1.0.tgz</span><br><span class="line">      version: 1.1.0</span><br><span class="line">generated: 2016-10-06T16:23:20.499029981-06:00</span><br></pre></td></tr></table></figure></p>
<p>生成的索引和包可以从基本的网络服务器提供。可以使用 helm serve 启动本地服务器，在本地测试所有内容。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm serve --repo-path ./charts</span><br><span class="line">Regenerating index. This may take a moment.</span><br><span class="line">Now serving you on 127.0.0.1:8879</span><br></pre></td></tr></table></figure></p>
<h2 id="托管-chart-库"><a href="#托管-chart-库" class="headerlink" title="托管 chart 库"></a>托管 chart 库</h2><p>要配置普通 Web 服务器来服务 Helm chart，只需执行以下操作：</p>
<ul>
<li>将索引和 chart 置于服务器目录中</li>
<li>确保 index.yaml 可以在没有认证要求的情况下访问</li>
<li>确保 yaml 文件的正确内容类型（text/yaml 或 text/x-yaml）</li>
</ul>
<p>例如，如果想在 $WEBROOT/charts 以外的目录为 chart 提供服务，请确保 Web 根目录中有一个 charts/ 目录，并将索引文件和 chart 放入该文件夹内。</p>
<h2 id="管理-chart-库"><a href="#管理-chart-库" class="headerlink" title="管理 chart 库"></a>管理 chart 库</h2><h3 id="将-chart-存储在-chart-库中"><a href="#将-chart-存储在-chart-库中" class="headerlink" title="将 chart 存储在 chart 库中"></a>将 chart 存储在 chart 库中</h3><p>现在已有一个 chart 存储库，让我们上传一个 chart 和一个索引文件到存储库。chart 库中的 chart 必须正确打包（helm package chart-name/）和版本（遵循 <a href="https://semver.org/" target="_blank" rel="noopener">SemVer 2</a> 标准）。</p>
<p>接下来的这些步骤是一个示例工作流程，也可以用你喜欢的任何工作流程来存储和更新 chart 库中的 chart。</p>
<p>准备好打包 chart 后，创建一个新目录，并将打包 chart 移动到该目录。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ helm package .</span><br><span class="line">$ mkdir emqx-charts</span><br><span class="line">$ mv emqx-0.1.0.tgz emqx-charts/</span><br><span class="line">$ helm repo index emqx-charts --url  https://example.com/charts</span><br></pre></td></tr></table></figure></p>
<p>最后一条命令采用刚创建的本地目录的路径和远程 chart 库的 URL，并在给定的目录路径中生成 index.yaml。</p>
<p>现在可以使用同步工具或手动将 chart 和索引文件上传到 chart 库。如果使用 Google 云端存储，请使用 gsutil 客户端查看此示例工作流程。对于 GitHub，可以简单地将 chart 放入适当的目标分支中。</p>
<h3 id="新添加-chart-添加到现有存储库"><a href="#新添加-chart-添加到现有存储库" class="headerlink" title="新添加 chart 添加到现有存储库"></a>新添加 chart 添加到现有存储库</h3><p>每次将新 chart 添加到存储库时，都必须重新生成索引。helm repo index 命令将 index.yaml 从头开始完全重建该文件，但仅包括它在本地找到的 chart。</p>
<p>可以使用 –merge 标志向现有 index.yaml 文件增量添加新 chart（在使用远程存储库（如 GCS）时，这是一个很好的选择）。运行 helm repo index –help 以了解更多信息，</p>
<p>确保上传修改后的 index.yaml 文件和 chart。如果生成了出处 provenance 文件，也要上传。</p>
<h3 id="与他人分享-chart"><a href="#与他人分享-chart" class="headerlink" title="与他人分享 chart"></a>与他人分享 chart</h3><p>准备好分享 chart 时，只需让别人知道存储库的 URL 是什么就可以了。</p>
<p>他们将通过 <code>helm repo add [NAME] [URL]</code> 命令将仓库添加到他们的 helm 客户端，并可以起一个带有任何想用来引用仓库的名字。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add emqx-charts https://example.com/charts</span><br><span class="line">$ helm repo list</span><br><span class="line">emqx-charts    https://example.com/charts</span><br></pre></td></tr></table></figure></p>
<p>如果 chart 由 HTTP 基本认证支持，也可以在此处提供用户名和密码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ helm repo add emqx-charts https://example.com/charts --username my-username --password my-password</span><br><span class="line">$ helm repo list</span><br><span class="line">emqx-charts    https://example.com/charts</span><br></pre></td></tr></table></figure></p>
<p><strong>注意</strong>： 如果存储库不包含有效信息库 index.yaml 文件，则添加不会成功。</p>
<p>之后，用户将能够搜索 chart。更新存储库后，他们可以使用该 helm repo update 命令获取最新的 chart 信息。</p>
<p>原理是helm repo add和helm repo update命令获取index.yaml文件并将它们存储在 $HELM_HOME/repository/cache/目录中。这是helm search 找到有关chart的信息的地方。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://whmzsu.github.io/helm-doc-zh-cn/chart/chart_repository-zh_cn.html" target="_blank" rel="noopener">Chart Repository 存储库指南</a></li>
<li><a href="https://www.jianshu.com/p/5db132101a09" target="_blank" rel="noopener">使用Helm管理kubernetes应用</a></li>
<li><a href="https://www.kubernetes.org.cn/4009.html" target="_blank" rel="noopener">Kunbernetes-容器云应用的安装部署工具Helm</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/25/kubernetes1-9安装dashboard，以及token认证问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/25/kubernetes1-9安装dashboard，以及token认证问题/" itemprop="url">kubernetes1.9安装dashboard，以及token认证问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-25T15:13:18+08:00">
                2018-10-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>dashboard的安装非常简单。但按照官网建议的方式安装完成后，输入token登录时会没有反应。 </p>
<p>这个问题困扰了我一整天，最终在<a href="https://github.com/kubernetes/dashboard/issues/2540l" target="_blank" rel="noopener">这里</a>找到了答案。 </p>
<p>原因如下： </p>
<p>按官方文档建议的方式安装完dashboard后，使用kubectl proxy代理的方式来访问webUI。使用这个代理的方式访问就会导致登录无响应的问题。</p>
<p>我们需要将dashboard的service类型改为NodePort,将端口映射到虚拟机上，然后直接通过虚拟机的ip地址登录</p>
<h2 id="安装dashboard"><a href="#安装dashboard" class="headerlink" title="安装dashboard"></a>安装dashboard</h2><h3 id="首先下载官网提供的dashboard-yaml"><a href="#首先下载官网提供的dashboard-yaml" class="headerlink" title="首先下载官网提供的dashboard.yaml"></a>首先下载官网提供的dashboard.yaml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<h3 id="修改yaml-添加NodePort"><a href="#修改yaml-添加NodePort" class="headerlink" title="修改yaml,添加NodePort."></a>修改yaml,添加NodePort.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  # 添加Service的type为NodePort</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      # 添加映射到虚拟机的端口,k8s只支持30000以上的端口</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br></pre></td></tr></table></figure>
<h3 id="安装dashboard-1"><a href="#安装dashboard-1" class="headerlink" title="安装dashboard"></a>安装dashboard</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>
<h3 id="获取token"><a href="#获取token" class="headerlink" title="获取token"></a>获取token</h3><p>这里有一个简单的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system describe $(kubectl -n kube-system get secret -n kube-system -o name | grep namespace) | grep token</span><br></pre></td></tr></table></figure></p>
<p>也可以自己手动查询：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 输入下面命令查询kube-system命名空间下的所有secret</span><br><span class="line">kubectl get secret -n kube-system</span><br><span class="line"></span><br><span class="line"># 然后获取token。只要是type为service-account-token的secret的token都可以使用。</span><br><span class="line"># 比如我们获取replicaset-controller-token-wsv4v的touken</span><br><span class="line">kubectl -n kube-system describe replicaset-controller-token-wsv4v</span><br></pre></td></tr></table></figure></p>
<h3 id="访问dashboard"><a href="#访问dashboard" class="headerlink" title="访问dashboard"></a>访问dashboard</h3><p>通过node节点的ip，加刚刚我们设置的nodePort就可以访问了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://&lt;node-ip&gt;:&lt;node-port&gt;</span><br></pre></td></tr></table></figure></p>
<p>认证有两种方式：</p>
<ul>
<li>通过我们刚刚获取的token直接认证</li>
<li><p>通过Kubeconfig文件认证</p>
<p>只需要在kubeadm生成的admin.conf文件末尾加上刚刚获取的token就好了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- name: kubernetes-admin</span><br><span class="line">user:</span><br><span class="line">  client-certificate-data: xxxxxxxx</span><br><span class="line">  client-key-data: xxxxxx</span><br><span class="line">  token: &quot;在这里加上token&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://segmentfault.com/a/1190000013681047" target="_blank" rel="noopener">kubernetes1.9安装dashboard，以及token认证问题</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/23/在k8s上搭建emqx自动集群/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/23/在k8s上搭建emqx自动集群/" itemprop="url">在k8s上搭建emqx自动集群</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-23T10:20:42+08:00">
                2018-10-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Emqx 支持通过Kubernetes 服务自动集群。在<a href="https://zhanghongtong.github.io/2018/10/09/ubuntu-%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes/">ubuntu 使用kubeadm安装kubernetes</a>中使用kubeadm搭建了一个三台节点的k8s集群，接来下在这个集群中使用Emqx的自动集群功能搭建一个emqx集群。</p>
<p>本文需要对k8s集群的资源如pods、services等有基本的概念，可以阅读<a href="https://kubernetes.io/docs/concepts/workloads/" target="_blank" rel="noopener">官方文档</a>来了解。</p>
<h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><ul>
<li>公有云环境：AWS EC2</li>
<li>操作系统：ubuntu 16.04</li>
<li>kubeadm version：v1.12.1</li>
<li>Docker version：18.6.1</li>
<li>集群节点<br>  |   hostname    |    节点角色   |   IP地址        |<br>  |   —         |    —    |   —             |<br>  |   kube-node1     |    master     |   172.31.18.155   |<br>  |   kube-node2     |    worker     |   172.31.21.171   |<br>  |   kube-node3     |    worker     |   172.31.20.189   |</li>
</ul>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="查看k8s集群状态"><a href="#查看k8s集群状态" class="headerlink" title="查看k8s集群状态"></a>查看k8s集群状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node -o wide</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION    CONTAINER-RUNTIME</span><br><span class="line">kube-node1   Ready    master   28h   v1.12.1   172.31.18.155   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br><span class="line">kube-node2   Ready    &lt;none&gt;   28h   v1.12.1   172.31.21.171   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br><span class="line">kube-node3   Ready    &lt;none&gt;   28h   v1.12.1   172.31.20.189   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br><span class="line"></span><br><span class="line">$ kubectl get pods --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP          NODE         NOMINATED NODE</span><br><span class="line">kube-system   coredns-576cbf47c7-b5xbb             1/1     Running   0          28h   10.244.0.5      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   coredns-576cbf47c7-g5s9j             1/1     Running   0          28h   10.244.0.4      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   etcd-kube-node1                      1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-kube-node1   1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-fscrm          1/1     Running   0          28h   172.31.20.189   kube-node3   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-hhj8b          1/1     Running   0          28h   172.31.21.171   kube-node2   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-l6ccn          1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-79thv                     1/1     Running   0          28h   172.31.20.189   kube-node3   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-ckg9t                     1/1     Running   0          28h   172.31.21.171   kube-node2   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-skq8m                     1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br></pre></td></tr></table></figure>
<h3 id="查看apiserver配置"><a href="#查看apiserver配置" class="headerlink" title="查看apiserver配置"></a>查看apiserver配置</h3><p>Emqx自动集群功能需要用到k8s的apiserver，先看一下apiserver的具体配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pods kube-apiserver-kube-node1 -n kube-system  </span><br><span class="line">Name:               kube-apiserver-kube-node1</span><br><span class="line">Namespace:          kube-system</span><br><span class="line">Priority:           2000000000</span><br><span class="line">PriorityClassName:  system-cluster-critical</span><br><span class="line">Node:               kube-node1/172.31.18.155</span><br><span class="line">Start Time:         Tue, 23 Oct 2018 02:29:37 +0000</span><br><span class="line">Labels:             component=kube-apiserver</span><br><span class="line">                    tier=control-plane</span><br><span class="line">Annotations:        kubernetes.io/config.hash: c5ac975e628056601100307026359ba8</span><br><span class="line">                    kubernetes.io/config.mirror: c5ac975e628056601100307026359ba8</span><br><span class="line">                    kubernetes.io/config.seen: 2018-10-17T02:00:07.757483468Z</span><br><span class="line">                    kubernetes.io/config.source: file</span><br><span class="line">                    scheduler.alpha.kubernetes.io/critical-pod: </span><br><span class="line">Status:             Running</span><br><span class="line">IP:                 172.31.18.155</span><br><span class="line">Containers:</span><br><span class="line">  kube-apiserver:</span><br><span class="line">    Container ID:  docker://d753a932b41ff8a99b6a11767d463f13af7e9de7526567df6eb5bd29a101f17b</span><br><span class="line">    Image:         k8s.gcr.io/kube-apiserver:v1.12.1</span><br><span class="line">    Image ID:      docker-pullable://k8s.gcr.io/kube-apiserver@sha256:52b9dae126b5a99675afb56416e9ae69239e012028668f7274e30ae16112bb1f</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      kube-apiserver</span><br><span class="line">      --authorization-mode=Node,RBAC</span><br><span class="line">      --advertise-address=172.31.18.155</span><br><span class="line">      --allow-privileged=true</span><br><span class="line">      --client-ca-file=/etc/kubernetes/pki/ca.crt</span><br><span class="line">      --enable-admission-plugins=NodeRestriction</span><br><span class="line">      --enable-bootstrap-token-auth=true</span><br><span class="line">      --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">      --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><br><span class="line">      --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><br><span class="line">      --etcd-servers=https://127.0.0.1:2379</span><br><span class="line">      --insecure-port=0</span><br><span class="line">      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><br><span class="line">      --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><br><span class="line">      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname</span><br><span class="line">      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt</span><br><span class="line">      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key</span><br><span class="line">      --requestheader-allowed-names=front-proxy-client</span><br><span class="line">      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class="line">      --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">      --requestheader-group-headers=X-Remote-Group</span><br><span class="line">      --requestheader-username-headers=X-Remote-User</span><br><span class="line">      --secure-port=6443</span><br><span class="line">      --service-account-key-file=/etc/kubernetes/pki/sa.pub</span><br><span class="line">      --service-cluster-ip-range=10.96.0.0/12</span><br><span class="line">      --tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><br><span class="line">      --tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Tue, 23 Oct 2018 02:29:39 +0000</span><br><span class="line">    Last State:     Terminated</span><br><span class="line">      Reason:       Completed</span><br><span class="line">      Exit Code:    0</span><br><span class="line">      Started:      Wed, 17 Oct 2018 02:00:09 +0000</span><br><span class="line">      Finished:     Thu, 18 Oct 2018 12:43:31 +0000</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  1</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        250m</span><br><span class="line">    Liveness:     http-get https://172.31.18.155:6443/healthz delay=15s timeout=15s period=10s #success=1 #failure=8</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /etc/ca-certificates from etc-ca-certificates (ro)</span><br><span class="line">      /etc/kubernetes/pki from k8s-certs (ro)</span><br><span class="line">      /etc/ssl/certs from ca-certs (ro)</span><br><span class="line">      /usr/local/share/ca-certificates from usr-local-share-ca-certificates (ro)</span><br><span class="line">      /usr/share/ca-certificates from usr-share-ca-certificates (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True </span><br><span class="line">  Ready             True </span><br><span class="line">  ContainersReady   True </span><br><span class="line">  PodScheduled      True </span><br><span class="line">Volumes:</span><br><span class="line">  k8s-certs:</span><br><span class="line">    Type:          HostPath (bare host directory volume)</span><br><span class="line">    Path:          /etc/kubernetes/pki</span><br><span class="line">    HostPathType:  DirectoryOrCreate</span><br><span class="line">  ca-certs:</span><br><span class="line">    Type:          HostPath (bare host directory volume)</span><br><span class="line">    Path:          /etc/ssl/certs</span><br><span class="line">    HostPathType:  DirectoryOrCreate</span><br><span class="line">  usr-share-ca-certificates:</span><br><span class="line">    Type:          HostPath (bare host directory volume)</span><br><span class="line">    Path:          /usr/share/ca-certificates</span><br><span class="line">    HostPathType:  DirectoryOrCreate</span><br><span class="line">  usr-local-share-ca-certificates:</span><br><span class="line">    Type:          HostPath (bare host directory volume)</span><br><span class="line">    Path:          /usr/local/share/ca-certificates</span><br><span class="line">    HostPathType:  DirectoryOrCreate</span><br><span class="line">  etc-ca-certificates:</span><br><span class="line">    Type:          HostPath (bare host directory volume)</span><br><span class="line">    Path:          /etc/ca-certificates</span><br><span class="line">    HostPathType:  DirectoryOrCreate</span><br><span class="line">QoS Class:         Burstable</span><br><span class="line">Node-Selectors:    &lt;none&gt;</span><br><span class="line">Tolerations:       :NoExecute</span><br><span class="line">Events:            &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>通过 <code>--advertise-address=172.31.18.155</code> 获得apiserver的IP地址（该地址在使用<code>kubeadm init</code> 命令创建集群的时候可以通过 <code>--apiserver-advertise-address=172.31.18.155</code> 参数来指定)，通过<code>--authorization-mode=Node,RBAC</code> 可以看到apiserver的访问规则为只有节点或者配置了合理的RBAC规则的pod可以访问。</p>
<h3 id="在节点上访问apiserver"><a href="#在节点上访问apiserver" class="headerlink" title="在节点上访问apiserver"></a>在节点上访问apiserver</h3><p>执行 <code>curl http://172.31.18.155:8080</code> 访问apiserver发现报错 <code>Connection refused</code>，使用 <code>netstat -apn | grep 8080</code>命令查看发现并没有进程监听8080端口。</p>
<p>执行<code>kubectl proxy --help</code>命令可以看到<code>kubectl proxy</code>可以在本机和apiserver之间创建一个代理服务器，它允许指定规则的http访问。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl proxy --accept-hosts=&quot;^.*$&quot; --address=&apos;172.31.18.155&apos; -p=8080 &amp;</span><br><span class="line">$ curl http://172.31.18.155:8080</span><br><span class="line">&#123;</span><br><span class="line">  &quot;paths&quot;: [</span><br><span class="line">    &quot;/api&quot;,</span><br><span class="line">    &quot;/api/v1&quot;,</span><br><span class="line">    &quot;/apis&quot;,</span><br><span class="line">    &quot;/apis/&quot;,</span><br><span class="line">    &quot;/apis/admissionregistration.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/admissionregistration.k8s.io/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/apiextensions.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/apiextensions.k8s.io/v1beta1&quot;,</span><br><span class="line">    &quot;/apis/apiregistration.k8s.io&quot;,</span><br><span class="line">    &quot;/apis/apiregistration.k8s.io/v1&quot;,</span><br><span class="line">    &quot;/apis/apiregistration.k8s.io/v1beta1&quot;,</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure></p>
<h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><p>kubectl可以通过 kubectl create -f xxx.yml来创建各种资源，那么只需要编写一个或多个合法的yml文件就可以创建emqx集群了。本文将所有资源都写在了一个yml文件中，在实际生产中，可以在一个目录下创建多个yml文件，并使用<code>kubectl create -f 目录名</code>来部署。<br>为了方便理解和学习，在本次实验中，将需要创建的资源类型和命名提前确定下来<br>|   资源类型         |   命名             |<br>|   ——–        |   —-            |<br>|   role            |   pod-reader      |<br>|   rolebinding     |   read-pods       |<br>|   serviceaccount  |   emqx-sa         |<br>|   service         |   emqx            |<br>|   deployment      |   emqx            |<br>|   pod             |   emqx            |</p>
<p>需要注意的是，一般来说service、deployment和pod最好命名为不同的名字以便区分，不过Emqx的自动集群功能需要将它们命名为统一的名字。</p>
<h3 id="Role"><a href="#Role" class="headerlink" title="Role"></a>Role</h3><p>上文我们查看了apiserver的配置，可以看到普通pod是没有权限访问apiserver的，必须要配置合法的RBAC规则策略才可以。</p>
<p>在RBAC API中，一个角色包含了一套表示一组权限的规则。 权限以纯粹的累加形式累积（没有”否定”的规则）。 角色可以由命名空间（namespace）内的Role对象定义，而整个Kubernetes集群范围内有效的角色则通过ClusterRole对象实现。</p>
<p>一个Role对象只能用于授予对某一单一命名空间中资源的访问权限。 以下示例描述了”default”命名空间中的一个Role对象的定义，用于授予对pod的读访问权限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: default</span><br><span class="line">  name: pod-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;] </span><br><span class="line">  resources: [&quot;&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span><br></pre></td></tr></table></figure></p>
<h3 id="RoleBinding"><a href="#RoleBinding" class="headerlink" title="RoleBinding"></a>RoleBinding</h3><p>角色绑定将一个角色中定义的各种权限授予一个或者一组用户。 角色绑定包含了一组相关主体（即subject, 包括用户——User、用户组——Group、或者服务账户——Service Account）以及对被授予角色的引用。 在命名空间中可以通过RoleBinding对象授予权限，而集群范围的权限授予则通过ClusterRoleBinding对象完成。</p>
<p>RoleBinding可以引用在同一命名空间内定义的Role对象。 下面示例中定义的RoleBinding对象在”default”命名空间中将”pod-reader”角色授予”emqx-sa”。 这一授权将允许”emqx-sa”从”default”命名空间中读取pod。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: read-pods</span><br><span class="line">  namespace: default</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: emqx-sa</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: pod-reader</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>
<h3 id="Service-Account"><a href="#Service-Account" class="headerlink" title="Service Account"></a>Service Account</h3><p>创建好了RBAC规则之后，还需要创建Service Account，Service Account概念的引入是基于这样的使用场景：运行在pod里的进程需要调用Kubernetes API以及非Kubernetes API的其它服务。Service Account它并不是给kubernetes集群的用户使用的，而是给pod里面的进程使用的，它为pod提供必要的身份认证。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get sa --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                 SECRETS   AGE</span><br><span class="line">default       default                              1         6d3h</span><br><span class="line">kube-public   default                              1         6d3h</span><br><span class="line">kube-system   attachdetach-controller              1         6d3h</span><br><span class="line">kube-system   bootstrap-signer                     1         6d3h</span><br><span class="line">kube-system   certificate-controller               1         6d3h</span><br><span class="line">kube-system   clusterrole-aggregation-controller   1         6d3h</span><br><span class="line">kube-system   coredns                              1         6d3h</span><br><span class="line">kube-system   cronjob-controller                   1         6d3h</span><br><span class="line">kube-system   daemon-set-controller                1         6d3h</span><br><span class="line">kube-system   default                              1         6d3h</span><br><span class="line">kube-system   deployment-controller                1         6d3h</span><br><span class="line">kube-system   disruption-controller                1         6d3h</span><br><span class="line">kube-system   endpoint-controller                  1         6d3h</span><br><span class="line">kube-system   expand-controller                    1         6d3h</span><br><span class="line">kube-system   flannel                              1         6d3h</span><br><span class="line">kube-system   generic-garbage-collector            1         6d3h</span><br><span class="line">kube-system   horizontal-pod-autoscaler            1         6d3h</span><br><span class="line">kube-system   job-controller                       1         6d3h</span><br><span class="line">kube-system   kube-proxy                           1         6d3h</span><br><span class="line">kube-system   namespace-controller                 1         6d3h</span><br><span class="line">kube-system   node-controller                      1         6d3h</span><br><span class="line">kube-system   persistent-volume-binder             1         6d3h</span><br><span class="line">kube-system   pod-garbage-collector                1         6d3h</span><br><span class="line">kube-system   pv-protection-controller             1         6d3h</span><br><span class="line">kube-system   pvc-protection-controller            1         6d3h</span><br><span class="line">kube-system   replicaset-controller                1         6d3h</span><br><span class="line">kube-system   replication-controller               1         6d3h</span><br><span class="line">kube-system   resourcequota-controller             1         6d3h</span><br><span class="line">kube-system   service-account-controller           1         6d3h</span><br><span class="line">kube-system   service-controller                   1         6d3h</span><br><span class="line">kube-system   statefulset-controller               1         6d3h</span><br><span class="line">kube-system   token-cleaner                        1         6d3h</span><br><span class="line">kube-system   ttl-controller                       1         6d3h</span><br></pre></td></tr></table></figure></p>
<p>如果kubernetes开启了ServiceAccount（–admission_control=…,ServiceAccount,… ）那么会在每个namespace下面都会创建一个默认的default的sa。<br>如下，其中最重要的就是secrets，它是每个sa下面都会拥有的一个加密的token，当用户再该namespace下创建pod的时候都会默认使用这个sa。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get sa  default  -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2018-10-17T02:00:36Z</span><br><span class="line">  name: default</span><br><span class="line">  namespace: default</span><br><span class="line">  resourceVersion: &quot;342&quot;</span><br><span class="line">  selfLink: /api/v1/namespaces/default/serviceaccounts/default</span><br><span class="line">  uid: 70ae05df-d1b0-11e8-bc24-0a7114fbf79e</span><br><span class="line">secrets:</span><br><span class="line">- name: default-token-7gd5l</span><br></pre></td></tr></table></figure></p>
<p>创建ServiceSAccount<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceSAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx-sa</span><br><span class="line">  namespace: default</span><br></pre></td></tr></table></figure></p>
<h3 id="Deployment-amp-amp-Pod"><a href="#Deployment-amp-amp-Pod" class="headerlink" title="Deployment &amp;&amp; Pod"></a>Deployment &amp;&amp; Pod</h3><p>查看<a href="http://emqtt.com/docs/v3/config.html#id7" target="_blank" rel="noopener">Emqx官方文档</a>中基于 Kubernetes 自动集群的相关配置，需要将<code>etc/emqx.conf</code>的配置做如下修改。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cluster.discovery = k8s</span><br><span class="line"></span><br><span class="line">##--------------------------------------------------------------------</span><br><span class="line">## Cluster with k8s</span><br><span class="line"></span><br><span class="line">cluster.k8s.apiserver = http://10.110.111.204:8080</span><br><span class="line"></span><br><span class="line">cluster.k8s.service_name = emqx</span><br><span class="line"></span><br><span class="line">## Address Type: ip | dns</span><br><span class="line">cluster.k8s.address_type = ip</span><br><span class="line"></span><br><span class="line">## The Erlang application name</span><br><span class="line">cluster.k8s.app_name = emqx</span><br><span class="line"></span><br><span class="line">## Kubernates Namespace</span><br><span class="line">cluster.k8s.namespace = default</span><br></pre></td></tr></table></figure></p>
<p>查看<a href="https://github.com/emqx/emqx-docker/blob/master/README.md" target="_blank" rel="noopener">Github上关于Emqx镜像的文档</a>，可以使用编辑环境变量的方式来修改<code>etc/emqx.conf</code>，根据上文所需的配置，我们可以指定如下环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- name: EMQX_CLUSTER__DISCOVERY</span><br><span class="line">    value: k8s</span><br><span class="line">- name: EMQX_NAME</span><br><span class="line">    value: emqx</span><br><span class="line">- name: EMQX_CLUSTER__K8S__APISERVER</span><br><span class="line">    value: http://172.31.19.161:8080</span><br><span class="line">- name: EMQX_CLUSTER__K8S__NAMESPACE</span><br><span class="line">    value: default</span><br><span class="line">- name: EMQX_CLUSTER__K8S__SERVICE_NAME</span><br><span class="line">    value: emqx</span><br><span class="line">- name: EMQX_CLUSTER__K8S__ADDRESS_TYPE</span><br><span class="line">    value: ip</span><br><span class="line">- name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">    value: emqx</span><br></pre></td></tr></table></figure>
<p>创建deployment和pod，因为k8s不能直接使用Dockerfile去编译镜像，只能从docker的镜像仓库中拉取，所以pod使用<a href="https://hub.docker.com/r/emqx/emqx/" target="_blank" rel="noopener">docker hub</a>的镜像。指定部署两个emqx镜像的pod，并指定pod的端口和环境变量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">  labels:</span><br><span class="line">        app: emqx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: emqx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: emqx</span><br><span class="line">        image: emqx/emqx:latest</span><br><span class="line">        ports:</span><br><span class="line">        - name: emqx-dashboard</span><br><span class="line">          containerPort: 18083</span><br><span class="line">        - name: emqx-http</span><br><span class="line">          containerPort: 8083</span><br><span class="line">        - name: emqx-mqtt</span><br><span class="line">          containerPort: 1883</span><br><span class="line">        env:</span><br><span class="line">        - name: EMQX_CLUSTER__DISCOVERY</span><br><span class="line">          value: k8s</span><br><span class="line">        - name: EMQX_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__APISERVER</span><br><span class="line">          value: http://172.31.19.161:8080</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__NAMESPACE</span><br><span class="line">          value: default</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__SERVICE_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__ADDRESS_TYPE</span><br><span class="line">          value: ip</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        tty: true</span><br></pre></td></tr></table></figure></p>
<h3 id="Servives"><a href="#Servives" class="headerlink" title="Servives"></a>Servives</h3><p>创建Service，方便访问Emqx的dashboard。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 32333</span><br><span class="line">    nodePort: 32333</span><br><span class="line">    targetPort:  emqx-dashboard</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: emqx</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure></p>
<h2 id="部署服务"><a href="#部署服务" class="headerlink" title="部署服务"></a>部署服务</h2><p>查看一下emqx.yml文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">cat emqx.yml</span><br><span class="line"></span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: default</span><br><span class="line">  name: pod-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;] </span><br><span class="line">  resources: [&quot;&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: read-pods</span><br><span class="line">  namespace: default</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: emqx-sa</span><br><span class="line">  apiGroup: &quot;&quot;</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: pod-reader</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx-sa</span><br><span class="line">  namespace: default</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 32333</span><br><span class="line">    nodePort: 32333</span><br><span class="line">    targetPort:  emqx-dashboard</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: emqx</span><br><span class="line">  type: NodePort</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: emqx</span><br><span class="line">  labels:</span><br><span class="line">        app: emqx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: emqx</span><br><span class="line">    spec:</span><br><span class="line">      nodeName: ip-172-31-23-51</span><br><span class="line">      containers:</span><br><span class="line">      - name: emqx</span><br><span class="line">        image: emqx/emqx:latest</span><br><span class="line">        ports:</span><br><span class="line">        - name: emqx-dashboard</span><br><span class="line">          containerPort: 18083</span><br><span class="line">        - name: emqx-http</span><br><span class="line">          containerPort: 8083</span><br><span class="line">        - name: emqx-mqtt</span><br><span class="line">          containerPort: 1883</span><br><span class="line">        env:</span><br><span class="line">        - name: EMQX_CLUSTER__DISCOVERY</span><br><span class="line">          value: k8s</span><br><span class="line">        - name: EMQX_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__APISERVER</span><br><span class="line">          value: http://172.31.19.161:8080</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__NAMESPACE</span><br><span class="line">          value: default</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__SERVICE_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__ADDRESS_TYPE</span><br><span class="line">          value: ip</span><br><span class="line">        - name: EMQX_CLUSTER__K8S__APP_NAME</span><br><span class="line">          value: emqx</span><br><span class="line">        tty: true</span><br></pre></td></tr></table></figure></p>
<p>部署emqx<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f emqx.yml </span><br><span class="line">role.rbac.authorization.k8s.io/pod-reader created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/read-pods created</span><br><span class="line">serviceaccount/emqx-sa created</span><br><span class="line">service/emqx created</span><br><span class="line">deployment.extensions/emqx created</span><br></pre></td></tr></table></figure></p>
<p>查看部署的状态，可以看到所有的资源都成功部署了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get all -o wide</span><br><span class="line">NAME                                  READY   STATUS        RESTARTS   AGE     IP            NODE         NOMINATED NODE</span><br><span class="line">pod/emqx-7685fc45cd-qmxlq             1/1     Running       0          3m22s   10.244.2.14   kube-node3   &lt;none&gt;</span><br><span class="line">pod/emqx-7685fc45cd-zq2cj             1/1     Running       0          3m22s   10.244.1.18   kube-node2   &lt;none&gt;</span><br><span class="line"></span><br><span class="line">NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)           AGE     SELECTOR</span><br><span class="line">service/emqx         NodePort    10.109.165.143   &lt;none&gt;        32333:32333/TCP   3m22s   app=emqx</span><br><span class="line">service/kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP           6d4h    &lt;none&gt;</span><br><span class="line"></span><br><span class="line">NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES             SELECTOR</span><br><span class="line">deployment.apps/emqx   2         2         2            2           3m22s   emqx         emqx/emqx:latest   app=emqx</span><br><span class="line"></span><br><span class="line">NAME                              DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES             SELECTOR</span><br><span class="line">replicaset.apps/emqx-7685fc45cd   2         2         2       3m22s   emqx         emqx/emqx:latest   app=emqx,pod-template-hash=7685fc45cd</span><br></pre></td></tr></table></figure></p>
<p>使用命令行查看集群状态，可以看到emqx已自动集群。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -it emqx-7685fc45cd-qmxlq /opt/emqx/bin/emqx_ctl cluster status</span><br><span class="line">Cluster status: [&#123;running_nodes,[&apos;emqx@10.244.1.18&apos;,&apos;emqx@10.244.2.14&apos;]&#125;]</span><br></pre></td></tr></table></figure></p>
<p>即使删掉一个pod，k8s也会自动创建出一个新的pod来自动集群<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete pod/emqx-7685fc45cd-zq2cj</span><br><span class="line">pod &quot;emqx-7685fc45cd-zq2cj&quot; deleted</span><br><span class="line"></span><br><span class="line">$ kubectl get pods </span><br><span class="line">NAME                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">emqx-7685fc45cd-nt54v   1/1     Running   0          56s</span><br><span class="line">emqx-7685fc45cd-qmxlq   1/1     Running   0          6m25</span><br><span class="line"></span><br><span class="line">$ kubectl exec -it emqx-7685fc45cd-qmxlq /opt/emqx/bin/emqx_ctl cluster status</span><br><span class="line">Cluster status: [&#123;running_nodes,[&apos;emqx@10.244.1.19&apos;,&apos;emqx@10.244.2.14&apos;]&#125;,</span><br><span class="line">                 &#123;stopped_nodes,[&apos;emqx@10.244.1.18&apos;]&#125;]</span><br></pre></td></tr></table></figure></p>
<p>打开浏览器，输入<code>http://任意节点的公网IP：32333</code>可以成功访问Emqx的dashboard页面。</p>
<p>参考资料</p>
<ul>
<li><a href="https://blog.csdn.net/u010278923/article/details/72857928" target="_blank" rel="noopener">kubernetes的Service Account和secret</a></li>
<li><a href="https://jimmysong.io/kubernetes-handbook/guide/rbac.html" target="_blank" rel="noopener">RBAC——基于角色的访问控制</a></li>
<li><a href="http://blog.51cto.com/ylw6006/2113542" target="_blank" rel="noopener">K8S使用dashboard管理集群</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/18/离线环境下使用二进制方式安装配置Kubernetes集群/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/18/离线环境下使用二进制方式安装配置Kubernetes集群/" itemprop="url">离线环境下使用二进制方式安装配置Kubernetes集群</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-18T15:11:38+08:00">
                2018-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Centos 7.3</li>
<li>Kubernetes的版本为 V1.10。</li>
<li>Docker版本为18.03.1-ce。</li>
<li>etcd 版本为 V3.3.8。</li>
</ul>
<h2 id="准备规划"><a href="#准备规划" class="headerlink" title="准备规划"></a>准备规划</h2><h3 id="1-Node-规划"><a href="#1-Node-规划" class="headerlink" title="1 Node 规划"></a>1 Node 规划</h3><table>
<thead>
<tr>
<th>主机名</th>
<th>地址</th>
<th>角色</th>
</tr>
</thead>
<tbody>
<tr>
<td>devops-101</td>
<td>192.168.0.101</td>
<td>k8s master</td>
</tr>
<tr>
<td>devops-102</td>
<td>192.168.0.102</td>
<td>k8s node</td>
</tr>
</tbody>
</table>
<h3 id="2-Network-网络"><a href="#2-Network-网络" class="headerlink" title="2 Network 网络"></a>2 Network 网络</h3><h3 id="3-安装文件"><a href="#3-安装文件" class="headerlink" title="3 安装文件"></a>3 安装文件</h3><p>Kubernetes安装需要以下二进制文件：</p>
<ul>
<li>etcd</li>
<li>docker</li>
<li>Kubernetes<ul>
<li>kubelet</li>
<li>kube-proxy</li>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-scheduler</li>
</ul>
</li>
</ul>
<p>我们可以下载编译好的二进制文件，也可以下载源码自己编译，源码编译可以参考这里本文只讨论二进制的安装方式。在Kubernetes的Github Latest 页面，可以看到最新打包的版本。也可以到 Tag 页面中找到自己需要的版本，我下载的是 V1.11。</p>
<p>注意这个页面有可能不是最新的版本，我查看的时候显示的版本是 V1.9.9，但是最新的版本是 V1.11，这时就需要切换到 Tag 页面查找。</p>
<p>服务器上需要的二进制文件并不在下载的 tar 包中，需要解压tar包，然后执行<code>cluster/get-kube-binaries.sh</code>。下载需要访问 storage.googleapis.com，因为大家都知道的原因，可能无法正常访问，需要大家科学的获取安装文件。下载完成后，解压<code>kubernetes-server-linux-amd64.tar.gz</code>。</p>
<p>可以看到文件列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@devops-101 bin]# pwd</span><br><span class="line">/root/kubernetes/server/bin</span><br><span class="line">[root@devops-101 bin]# ls -lh</span><br><span class="line">total 1.8G</span><br><span class="line">-rwxr-xr-x. 1 root root  57M Jun 28 04:55 apiextensions-apiserver</span><br><span class="line">-rwxr-xr-x. 1 root root 132M Jun 28 04:55 cloud-controller-manager</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 cloud-controller-manager.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root 134M Jun 28 04:55 cloud-controller-manager.tar</span><br><span class="line">-rwxr-xr-x. 1 root root 218M Jun 28 04:55 hyperkube</span><br><span class="line">-rwxr-xr-x. 1 root root  56M Jun 28 04:55 kube-aggregator</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 kube-aggregator.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root  57M Jun 28 04:55 kube-aggregator.tar</span><br><span class="line">-rwxr-xr-x. 1 root root 177M Jun 28 04:55 kube-apiserver</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 kube-apiserver.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root 179M Jun 28 04:55 kube-apiserver.tar</span><br><span class="line">-rwxr-xr-x. 1 root root 147M Jun 28 04:55 kube-controller-manager</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 kube-controller-manager.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root 149M Jun 28 04:55 kube-controller-manager.tar</span><br><span class="line">-rwxr-xr-x. 1 root root  50M Jun 28 04:55 kube-proxy</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 kube-proxy.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root  96M Jun 28 04:55 kube-proxy.tar</span><br><span class="line">-rwxr-xr-x. 1 root root  54M Jun 28 04:55 kube-scheduler</span><br><span class="line">-rw-r--r--. 1 root root    8 Jun 28 04:55 kube-scheduler.docker_tag</span><br><span class="line">-rw-r--r--. 1 root root  55M Jun 28 04:55 kube-scheduler.tar</span><br><span class="line">-rwxr-xr-x. 1 root root  55M Jun 28 04:55 kubeadm</span><br><span class="line">-rwxr-xr-x. 1 root root  53M Jun 28 04:56 kubectl</span><br><span class="line">-rwxr-xr-x. 1 root root 156M Jun 28 04:55 kubelet</span><br><span class="line">-rwxr-xr-x. 1 root root 2.3M Jun 28 04:55 mounter</span><br></pre></td></tr></table></figure></p>
<h3 id="4-系统配置"><a href="#4-系统配置" class="headerlink" title="4 系统配置"></a>4 系统配置</h3><ul>
<li>配置Hosts</li>
<li><p>关闭防火墙</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld</span><br><span class="line">$ systemctl disable firewalld</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭selinux</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/selinux/config</span><br></pre></td></tr></table></figure>
<p>  将SELINUX=enforcing改为SELINUX=disabled，wq保存退出。</p>
</li>
<li><p>关闭swap</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ swapoff -a</span><br><span class="line">$ vim /etc/fstab #修改自动挂载配置，注释掉即可</span><br><span class="line">#/dev/mapper/centos-swap swap   swap    defaults    0 0</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="安装-Node"><a href="#安装-Node" class="headerlink" title="安装 Node"></a>安装 Node</h2><p>我们需要在Node机器上安装以下应用：</p>
<ul>
<li>Docker</li>
<li>kubelet</li>
<li>kube-proxy</li>
</ul>
<h3 id="1-Docker"><a href="#1-Docker" class="headerlink" title="1 Docker"></a>1 Docker</h3><p>Docker的版本需要与kubelete版本相对应，最好都使用最新的版本。Redhat 中需要使用 Static Binary 方式安装，具体可以参考我之前的一篇文章。</p>
<h3 id="2-拷贝-kubelet、kube-proxy"><a href="#2-拷贝-kubelet、kube-proxy" class="headerlink" title="2 拷贝 kubelet、kube-proxy"></a>2 拷贝 kubelet、kube-proxy</h3><p>在之前解压的 kubernetes 文件夹中拷贝二进制文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp /root/kubernetes/server/bin/kubelet /usr/bin/</span><br><span class="line">$ cp /root/kubernetes/server/bin/kube-proxy /usr/bin/</span><br></pre></td></tr></table></figure></p>
<h3 id="3-安装-kube-proxy-服务"><a href="#3-安装-kube-proxy-服务" class="headerlink" title="3 安装 kube-proxy 服务"></a>3 安装 kube-proxy 服务</h3><p>创建service文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/etc/kubernetes/config</span><br><span class="line">EnvironmentFile=/etc/kubernetes/proxy</span><br><span class="line">ExecStart=/usr/bin/kube-proxy \</span><br><span class="line">            $KUBE_LOGTOSTDERR \</span><br><span class="line">            $KUBE_LOG_LEVEL \</span><br><span class="line">            $KUBE_MASTER \</span><br><span class="line">            $KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>创建配置目录，并添加配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /etc/kubernetes</span><br><span class="line">$ vim /etc/kubernetes/proxy</span><br><span class="line">KUBE_PROXY_ARGS=&quot;&quot;</span><br><span class="line">$ vim /etc/kubernetes/config</span><br><span class="line">KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;</span><br><span class="line">KUBE_LOG_LEVEL=&quot;--v=0&quot;</span><br><span class="line">KUBE_ALLOW_PRIV=&quot;--allow_privileged=false&quot;</span><br><span class="line">KUBE_MASTER=&quot;--master=http://192.168.0.101:8080&quot;</span><br></pre></td></tr></table></figure></p>
<p>启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@devops-102 ~]# systemctl daemon-reload</span><br><span class="line">[root@devops-102 ~]# systemctl start kube-proxy.service</span><br><span class="line">[root@devops-102 ~]# netstat -lntp | grep kube-proxy</span><br><span class="line">tcp        0      0 127.0.0.1:10249         0.0.0.0:*               LISTEN      10522/kube-proxy    </span><br><span class="line">tcp6       0      0 :::10256                :::*                    LISTEN      10522/kube-proxy</span><br></pre></td></tr></table></figure></p>
<h3 id="4-安装-kubelete-服务"><a href="#4-安装-kubelete-服务" class="headerlink" title="4 安装 kubelete 服务"></a>4 安装 kubelete 服务</h3><p>创建service文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=/etc/kubernetes/kubelet</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">$ mkdir -p /var/lib/kubelet</span><br><span class="line">$ vim /etc/kubernetes/kubelet</span><br><span class="line">KUBELET_ADDRESS=&quot;--address=0.0.0.0&quot;</span><br><span class="line">KUBELET_HOSTNAME=&quot;--hostname-override=192.168.0.102&quot;</span><br><span class="line">KUBELET_API_SERVER=&quot;--api-servers=http://192.168.0.101:8080&quot;</span><br><span class="line">KUBELET_POD_INFRA_CONTAINER=&quot;--pod-infra-container-image=reg.docker.tb/harbor/pod-infrastructure:latest&quot;</span><br><span class="line">KUBELET_ARGS=&quot;--enable-server=true --enable-debugging-handlers=true --fail-swap-on=false --kubeconfig=/var/lib/kubelet/kubeconfig&quot;</span><br></pre></td></tr></table></figure></p>
<p>创建配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ vim /var/lib/kubelet/kubeconfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Config</span><br><span class="line">users:</span><br><span class="line">- name: kubelet</span><br><span class="line">clusters:</span><br><span class="line">- name: kubernetes</span><br><span class="line">  cluster:</span><br><span class="line">    server: http://192.168.0.101:8080</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kubelet</span><br><span class="line">  name: service-account-context</span><br><span class="line">current-context: service-account-context</span><br></pre></td></tr></table></figure></p>
<p>启动kubelet并进习验证。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ swapoff -a</span><br><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start kubelet.service</span><br><span class="line">$ netstat -tnlp | grep kubelet</span><br><span class="line">tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      10630/kubelet       </span><br><span class="line">tcp        0      0 127.0.0.1:37865         0.0.0.0:*               LISTEN      10630/kubelet       </span><br><span class="line">tcp6       0      0 :::10250                :::*                    LISTEN      10630/kubelet       </span><br><span class="line">tcp6       0      0 :::10255                :::*                    LISTEN      10630/kubelet</span><br></pre></td></tr></table></figure></p>
<h2 id="安装-Master"><a href="#安装-Master" class="headerlink" title="安装 Master"></a>安装 Master</h2><h3 id="1-安装etcd"><a href="#1-安装etcd" class="headerlink" title="1 安装etcd"></a>1 安装etcd</h3><p>本文采用二进制安装方法，首先<a href="https://github.com/etcd-io/etcd/releases" target="_blank" rel="noopener">下载</a>安装包。<br>之后进行解压，文件拷贝，编辑 etcd.service、etcd.conf文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ tar zxf etcd-v3.2.11-linux-amd64.tar.gz</span><br><span class="line">$ cd etcd-v3.2.11-linux-amd64</span><br><span class="line">$ cp etcd etcdctl /usr/bin/</span><br><span class="line">$ vim /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=etcd.service</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Restart=always</span><br><span class="line">WorkingDirectory=/var/lib/etcd</span><br><span class="line">EnvironmentFile=-/etc/etcd/etcd.conf</span><br><span class="line">ExecStart=/usr/bin/etcd</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">$ mkdir -p /var/lib/etcd &amp;&amp; mkdir -p /etc/etcd/</span><br><span class="line">$ vim /etc/etcd/etcd.conf</span><br><span class="line">ETCD_NAME=ETCD Server</span><br><span class="line">ETCD_DATA_DIR=&quot;/var/lib/etcd/&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.0.101:2379&quot;</span><br><span class="line"># 启动etcd</span><br><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start etcd.service</span><br></pre></td></tr></table></figure></p>
<p>查看etcd状态是否正常<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl cluster-health</span><br><span class="line">member 8e9e05c52164694d is healthy: got healthy result from http://192.168.0.101:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure></p>
<h3 id="2-安装kube-apiserver"><a href="#2-安装kube-apiserver" class="headerlink" title="2 安装kube-apiserver"></a>2 安装kube-apiserver</h3><p>添加启动文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/etc/kubernetes/apiserver</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver  \</span><br><span class="line">        $KUBE_ETCD_SERVERS \</span><br><span class="line">        $KUBE_API_ADDRESS \</span><br><span class="line">        $KUBE_API_PORT \</span><br><span class="line">        $KUBE_SERVICE_ADDRESSES \</span><br><span class="line">        $KUBE_ADMISSION_CONTROL \</span><br><span class="line">        $KUBE_API_LOG \</span><br><span class="line">        $KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>创建配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/kubernetes/apiserver </span><br><span class="line">KUBE_API_ADDRESS=&quot;--insecure-bind-address=0.0.0.0&quot;</span><br><span class="line">KUBE_API_PORT=&quot;--port=8080&quot;</span><br><span class="line">KUBELET_PORT=&quot;--kubelet-port=10250&quot;</span><br><span class="line">KUBE_ETCD_SERVERS=&quot;--etcd-servers=http://192.168.0.101:2379&quot;</span><br><span class="line">KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.0.0.0/24&quot;</span><br><span class="line">KUBE_ADMISSION_CONTROL=&quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&quot;</span><br><span class="line">KUBE_API_ARGS=&quot;&quot;</span><br></pre></td></tr></table></figure></p>
<p>启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start kube-apiserver.service</span><br></pre></td></tr></table></figure></p>
<p>查看启动是否成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -tnlp | grep kube</span><br><span class="line">tcp6       0      0 :::6443                 :::*                    LISTEN      10144/kube-apiserve </span><br><span class="line">tcp6       0      0 :::8080                 :::*                    LISTEN      10144/kube-apiserve</span><br></pre></td></tr></table></figure></p>
<p>3.3 安装kube-controller-manager<br>创建启动文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/controller-manager</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager \</span><br><span class="line">        $KUBE_MASTER \</span><br><span class="line">        $KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>创建配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/kubernetes/controller-manager</span><br><span class="line">KUBE_MASTER=&quot;--master=http://192.168.0.101:8080&quot;</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=&quot; &quot;</span><br></pre></td></tr></table></figure></p>
<p>启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start kube-controller-manager.service</span><br></pre></td></tr></table></figure></p>
<p>验证服务状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -lntp | grep kube-controll</span><br><span class="line">tcp6       0      0 :::10252                :::*                    LISTEN      10163/kube-controll</span><br></pre></td></tr></table></figure></p>
<h3 id="4-安装kube-scheduler"><a href="#4-安装kube-scheduler" class="headerlink" title="4 安装kube-scheduler"></a>4 安装kube-scheduler</h3><p>创建启动文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=root</span><br><span class="line">EnvironmentFile=/etc/kubernetes/scheduler</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler \</span><br><span class="line">        $KUBE_MASTER \</span><br><span class="line">        $KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>修改配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/kubernetes/scheduler</span><br><span class="line">KUBE_MASTER=&quot;--master=http://192.168.0.101:8080&quot;</span><br><span class="line">KUBE_SCHEDULER_ARGS=&quot;--logtostderr=true --log-dir=/home/log/kubernetes --v=2&quot;</span><br></pre></td></tr></table></figure></p>
<p>启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start kube-scheduler.service</span><br></pre></td></tr></table></figure></p>
<p>验证服务状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ netstat -lntp | grep kube-schedule</span><br><span class="line">tcp6       0      0 :::10251                :::*                    LISTEN      10179/kube-schedule</span><br></pre></td></tr></table></figure></p>
<h3 id="5-配置Profile"><a href="#5-配置Profile" class="headerlink" title="5 配置Profile"></a>5 配置Profile</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sed -i &apos;$a export PATH=$PATH:/root/kubernetes/server/bin/&apos; /etc/profile</span><br><span class="line">$ source /etc/profile</span><br></pre></td></tr></table></figure>
<h3 id="6-安装-kubectl-并查看状态"><a href="#6-安装-kubectl-并查看状态" class="headerlink" title="6 安装 kubectl 并查看状态"></a>6 安装 kubectl 并查看状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cp /root/kubernetes/server/bin/kubectl /usr/bin/</span><br><span class="line">$ kubectl get cs</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok</span><br></pre></td></tr></table></figure>
<p>到这里Master节点就配置完毕。</p>
<h2 id="配置flannel网络"><a href="#配置flannel网络" class="headerlink" title="配置flannel网络"></a>配置flannel网络</h2><p>Flannel可以使整个集群的docker容器拥有唯一的内网IP，并且多个node之间的docker0可以互相访问，所以每个节点都需要安装flannel。centos下可以直接使用 <code>yum install flanneld</code></p>
<h2 id="集群验证"><a href="#集群验证" class="headerlink" title="集群验证"></a>集群验证</h2><p>在master 节点上执行命令，检查nodes，如果能看到，表明集群现在已经OK了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME         STATUS    ROLES     AGE       VERSION</span><br><span class="line">devops-102   Ready     &lt;none&gt;    12s       v1.11.0</span><br></pre></td></tr></table></figure></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://www.cnblogs.com/cocowool/p/install_k8s_offline.html" target="_blank" rel="noopener">离线环境下使用二进制方式安装配置Kubernetes集群</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/09/ubuntu-使用kubeadm安装kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/ubuntu-使用kubeadm安装kubernetes/" itemprop="url">ubuntu 使用kubeadm安装kubernetes</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T15:01:38+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="kubeadm-介绍"><a href="#kubeadm-介绍" class="headerlink" title="kubeadm 介绍"></a>kubeadm 介绍</h2><p>kubeadm 是一个工具包，可帮助您以简单，合理安全和可扩展的方式引导最佳实践Kubernetes群集。它还支持为您管理Bootstrap Tokens并升级/降级群集。</p>
<p>kubeadm的目标是建立一个通过Kubernetes一致性测试Kubernetes Conformance tests的最小可行集群 ，但不会安装其他功能插件。</p>
<p>它在设计上并未为您安装网络解决方案，需要用户自行安装第三方符合CNI的网络解决方案（如flanal，calico，canal等）。</p>
<p>kubeadm可以在多种设备上运行，可以是Linux笔记本电脑，虚拟机，物理/云服务器或Raspberry Pi。这使得kubeadm非常适合与不同种类的配置系统（例如Terraform，Ansible等）集成。</p>
<p>kubeadm是一种简单的方式让新用户开始尝试Kubernetes，也可能是第一次让现有用户轻松测试他们的应用程序并缝合到一起的方式，也可以作为其他生态系统中的构建块，或者具有更大范围的安装工具。</p>
<p>可以在支持安装deb或rpm软件包的操作系统上非常轻松地安装kubeadm。SIG集群生命周期SIG Cluster Lifecycle kubeadm的SIG相关维护者提供了预编译的这些软件包，也可以在其他操作系统上使用。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ol>
<li>本文所用的环境：</li>
</ol>
<ul>
<li>公有云环境：AWS EC2</li>
<li>操作系统：ubuntu 16.04 minimal 安装</li>
<li>网络规划：<ul>
<li>kube-node1：172.31.18.155</li>
<li>kube-node2：172.31.21.171</li>
<li>kube-node3：172.31.20.189</li>
</ul>
</li>
</ul>
<ol start="2">
<li><p><a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" target="_blank" rel="noopener">安装docker</a></p>
</li>
<li><p>设置国内下载源</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">EOF  </span><br><span class="line">apt-get update</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 kubeadm、kubectl、kubelet</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y kubelet kubeadm=1.12.0-00 kubectl</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>本次实验指定 kubeadm 的版本为 1.12.0，可以使用 <code>apt-cache madison kubeadm</code> 命令查看可用的 kubeadm 版本</p>
<h2 id="配置master节点"><a href="#配置master节点" class="headerlink" title="配置master节点"></a>配置master节点</h2><p>因为国内没办法访问Google的镜像源，变通的方法是从其他镜像源下载后，修改tag。执行下面这个Shell脚本即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">images=(k8s.gcr.io/kube-apiserver:v1.12.0</span><br><span class="line">        k8s.gcr.io/kube-controller-manager:v1.12.0</span><br><span class="line">        k8s.gcr.io/kube-scheduler:v1.12.0</span><br><span class="line">        k8s.gcr.io/kube-proxy:v1.12.0</span><br><span class="line">        k8s.gcr.io/pause:3.1</span><br><span class="line">        k8s.gcr.io/etcd:3.2.24</span><br><span class="line">        k8s.gcr.io/coredns:1.2.2)</span><br><span class="line"></span><br><span class="line">for var in $&#123;images[@]&#125;;do</span><br><span class="line">        image=$&#123;var/k8s.gcr.io\//anjia0532\/google-containers.&#125;</span><br><span class="line">        docker pull $&#123;image&#125;</span><br><span class="line">        docker tag $&#123;image&#125; $&#123;var&#125;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">docker pull coredns/coredns:1.2.2</span><br><span class="line">docker tag coredns/coredns:1.2.2 k8s.gcr.io/coredns:1.2.2</span><br></pre></td></tr></table></figure></p>
<p>PS: 如果是其他的kubeadm的版本，可以执行 <code>kubeadm config image list</code> 命令查看所需要的镜像，然后下载相应的镜像即可。（该命令可能需要翻墙）</p>
<p>接下来执行Master节点的初始化，首选需要制定kuberneter的版本，不然kubeadm会去墙外的网站查询从而导致超时，接下来需要指定apiserver的监听地址，另外我们打算使用flannel网络插件，根据<a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">官方文档</a>，需要指定–pod-network-cidr=10.244.0.0/16。（如果安装calico网络，则需要指定–pod-network-cidr=192.168.0.0/16）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">$ sudo kubeadm init --kubernetes-version=v1.12.0 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=172.31.18.155</span><br><span class="line"></span><br><span class="line">[init] using Kubernetes version: v1.11.0</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">I0724 08:36:35.636931    3409 kernel_validator.go:81] Validating kernel version</span><br><span class="line">I0724 08:36:35.637052    3409 kernel_validator.go:96] Validating kernel config</span><br><span class="line">	[WARNING Hostname]: hostname &quot;devops-101&quot; could not be reached</span><br><span class="line">	[WARNING Hostname]: hostname &quot;devops-101&quot; lookup devops-101 on 172.20.10.1:53: no such host</span><br><span class="line">	[WARNING Service-Kubelet]: kubelet service is not enabled, please run &apos;systemctl enable kubelet.service&apos;</span><br><span class="line">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[certificates] Generated ca certificate and key.</span><br><span class="line">[certificates] Generated apiserver certificate and key.</span><br><span class="line">[certificates] apiserver serving cert is signed for DNS names [devops-101 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.101]</span><br><span class="line">[certificates] Generated apiserver-kubelet-client certificate and key.</span><br><span class="line">[certificates] Generated sa key and public key.</span><br><span class="line">[certificates] Generated front-proxy-ca certificate and key.</span><br><span class="line">[certificates] Generated front-proxy-client certificate and key.</span><br><span class="line">[certificates] Generated etcd/ca certificate and key.</span><br><span class="line">[certificates] Generated etcd/server certificate and key.</span><br><span class="line">[certificates] etcd/server serving cert is signed for DNS names [devops-101 localhost] and IPs [127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/peer certificate and key.</span><br><span class="line">[certificates] etcd/peer serving cert is signed for DNS names [devops-101 localhost] and IPs [192.168.0.101 127.0.0.1 ::1]</span><br><span class="line">[certificates] Generated etcd/healthcheck-client certificate and key.</span><br><span class="line">[certificates] Generated apiserver-etcd-client certificate and key.</span><br><span class="line">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class="line">[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class="line">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class="line">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class="line">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot; </span><br><span class="line">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class="line">[apiclient] All control plane components are healthy after 46.002877 seconds</span><br><span class="line">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[markmaster] Marking the node devops-101 as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[markmaster] Marking the node devops-101 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;devops-101&quot; as an annotation</span><br><span class="line">[bootstraptoken] using token: wkj0bo.pzibll6rd9gyi5z8</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 172.31.18.155:6443 --token rje1gq.9zohjsh8mjxp90oj --discovery-token-ca-cert-hash sha256:54ad5605a76cf7818443d5db849e0da9a076bed7e1a367d54b4019166e930285</span><br></pre></td></tr></table></figure></p>
<p>看到以上信息表示Master节点已经初始化成功了，按照提示配置 kubectl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p $HOME/.kube</span><br><span class="line">$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></p>
<p>查看一下集群状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get cs</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p>确认个组件都处于healthy状态。</p>
<p>集群初始化如果遇到问题，可以使用下面的命令进行清理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm reset</span><br><span class="line">$ ifconfig cni0 down</span><br><span class="line">$ ip link delete cni0</span><br><span class="line">$ ifconfig flannel.1 down</span><br><span class="line">$ ip link delete flannel.1</span><br><span class="line">$ rm -rf /var/lib/cni/</span><br></pre></td></tr></table></figure></p>
<p>查看k8s状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME         STATUS     ROLES    AGE   VERSION</span><br><span class="line">kube-node1   NotReady   master   72s   v1.12.1 </span><br><span class="line"></span><br><span class="line">$ kubectl get pods --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE   IP          NODE         NOMINATED NODE</span><br><span class="line">kube-system   coredns-576cbf47c7-b5xbb             1/1     Pending   0          28h   10.244.0.5      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   coredns-576cbf47c7-g5s9j             1/1     Pending   0          28h   10.244.0.4      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   etcd-kube-node1                      1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-kube-node1   1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-skq8m                     1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>可以看到节点还没有Ready，dns的两个pod也没不正常，还需要安装网络配置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line">$ kubectl apply -f  kube-flannel.yml</span><br></pre></td></tr></table></figure></p>
<p>如果Node有多个网卡的话，参考flannel issues 39701，目前需要在kube-flannel.yml中使用–iface参数指定集群主机内网网卡的名称，否则可能会出现dns无法解析。需要将kube-flannel.yml下载到本地，flanneld启动参数加上–iface=\<iface-name><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">        command:</span><br><span class="line">        - /opt/bin/flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        - --iface=eth0</span><br><span class="line">......</span><br></pre></td></tr></table></figure></iface-name></p>
<p>执行成功后，Master并不能马上变成Ready状态，稍等几分钟，就可以看到所有状态都正常了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide</span><br><span class="line">kube-system   coredns-576cbf47c7-b5xbb             1/1     Running   0          28h   10.244.0.5      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   coredns-576cbf47c7-g5s9j             1/1     Running   0          28h   10.244.0.4      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   etcd-kube-node1                      1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-kube-node1   1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-l6ccn          1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-skq8m                     1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">$ kubectl get node -o wide</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION    CONTAINER-RUNTIME</span><br><span class="line">kube-node1   Ready    master   28h   v1.12.1   172.31.18.155   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br></pre></td></tr></table></figure></p>
<p>至此，k8s的master节点初始化完毕</p>
<h2 id="配置worker节点"><a href="#配置worker节点" class="headerlink" title="配置worker节点"></a>配置worker节点</h2><p>worker节点参照本文前期的准备工作安装好 kubectl、kubeadm、kubelet, 并下载镜像（worker节点只需要下载 k8s.gcr.io/pause:3.1和 k8s.gcr.io/kube-proxy:v1.12.0 即可）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">images=(k8s.gcr.io/kube-proxy:v1.12.0</span><br><span class="line">        k8s.gcr.io/pause:3.1)</span><br><span class="line"></span><br><span class="line">for var in $&#123;images[@]&#125;;do</span><br><span class="line">        image=$&#123;var/k8s.gcr.io\//anjia0532\/google-containers.&#125;</span><br><span class="line">        docker pull $&#123;image&#125;</span><br><span class="line">        docker tag $&#123;image&#125; $&#123;var&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>根据Master节点的提示加入集群。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$sudo kubeadm join 172.31.18.155:6443 --token rje1gq.9zohjsh8mjxp90oj --discovery-token-ca-cert-hash </span><br><span class="line"></span><br><span class="line">sha256:54ad5605a76cf7818443d5db849e0da9a076bed7e1a367d54b4019166e930285</span><br><span class="line">[preflight] running pre-flight checks</span><br><span class="line">	[WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh] or no builtin kernel ipvs support: map[ip_vs:&#123;&#125; ip_vs_rr:&#123;&#125; ip_vs_wrr:&#123;&#125; ip_vs_sh:&#123;&#125; nf_conntrack_ipv4:&#123;&#125;]</span><br><span class="line">you can solve this problem with following methods:</span><br><span class="line"> 1. Run &apos;modprobe -- &apos; to load missing kernel modules;</span><br><span class="line">2. Provide the missing builtin kernel ipvs support</span><br><span class="line"></span><br><span class="line">[discovery] Trying to connect to API Server &quot;172.31.18.155:6443&quot;</span><br><span class="line">[discovery] Created cluster-info discovery client, requesting info from &quot;https://172.31.18.155:6443&quot;</span><br><span class="line">[discovery] Requesting info from &quot;https://172.31.18.155:6443&quot; again to validate TLS against the pinned public key</span><br><span class="line">[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;172.31.18.155:6443&quot;</span><br><span class="line">[discovery] Successfully established connection with API Server &quot;172.31.18.155:6443&quot;</span><br><span class="line">[kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.12&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[preflight] Activating the kubelet service</span><br><span class="line">[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;k8s-worker&quot; as an annotation</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the master to see this node join the cluster.</span><br></pre></td></tr></table></figure></p>
<p>节点的启动也需要一点时间，稍后再到Master上查看状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP          NODE         NOMINATED NODE</span><br><span class="line">kube-system   coredns-576cbf47c7-b5xbb             1/1     Running   0          28h   10.244.0.5      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   coredns-576cbf47c7-g5s9j             1/1     Running   0          28h   10.244.0.4      kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   etcd-kube-node1                      1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-kube-node1   1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-fscrm          1/1     Running   0          28h   172.31.20.189   kube-node3   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-hhj8b          1/1     Running   0          28h   172.31.21.171   kube-node2   &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-l6ccn          1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-79thv                     1/1     Running   0          28h   172.31.20.189   kube-node3   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-ckg9t                     1/1     Running   0          28h   172.31.21.171   kube-node2   &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-skq8m                     1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-kube-node1            1/1     Running   0          28h   172.31.18.155   kube-node1   &lt;none&gt;</span><br><span class="line"></span><br><span class="line">$ kubectl get node -o wide</span><br><span class="line">NAME         STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION    CONTAINER-RUNTIME</span><br><span class="line">kube-node1   Ready    master   28h   v1.12.1   172.31.18.155   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br><span class="line">kube-node2   Ready    &lt;none&gt;   28h   v1.12.1   172.31.21.171   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br><span class="line">kube-node3   Ready    &lt;none&gt;   28h   v1.12.1   172.31.20.189   &lt;none&gt;        Ubuntu 18.04.1 LTS   4.15.0-1021-aws   docker://18.6.1</span><br></pre></td></tr></table></figure></p>
<p>至此，k8s集群创建完毕。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://anjia0532.github.io/2017/11/15/gcr-io-image-mirror/" target="_blank" rel="noopener">Google Container Registry(gcr.io) 中国可用镜像(长期维护)</a></li>
<li><a href="http://blog.51cto.com/355665/2178181" target="_blank" rel="noopener">kubeadm安装踩坑</a></li>
<li><a href="https://www.cnblogs.com/cocowool/p/kubeadm_install_kubernetes.html" target="_blank" rel="noopener">kubeadm安装kubernetes V1.11.1 集群</a></li>
<li><a href="https://www.kubernetes.org.cn/4619.html" target="_blank" rel="noopener">使用kubeadm安装Kubernetes 1.12</a></li>
</ul>
<h2 id="一些坑"><a href="#一些坑" class="headerlink" title="一些坑"></a>一些坑</h2><ol start="0">
<li><p>在公有云上部署flannel网络可能会出现无法跨主机ping flannel网卡的情况，以AWS为例，需要在安全组里面开放8472的UDP端口，因为flannel 使用 vxlan 技术为各节点创建网络，vxlan使用8472端口作为UDP封装报文的端口，所以需要开放8472 UDP端口。</p>
</li>
<li><p>安装 kubeadm 或 kubelet 的时候可能会遇到 <code>kubelet : Depends: kubernetes-cni (= 0.6.0) but 0.6.0-02 is to be installed</code> 的错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install kubelet </span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree       </span><br><span class="line">Reading state information... Done</span><br><span class="line">Some packages could not be installed. This may mean that you have</span><br><span class="line">requested an impossible situation or if you are using the unstable</span><br><span class="line">distribution that some required packages have not yet been created</span><br><span class="line">or been moved out of Incoming.</span><br><span class="line">The following information may help to resolve the situation:</span><br><span class="line"></span><br><span class="line">The following packages have unmet dependencies:</span><br><span class="line">kubelet : Depends: kubernetes-cni (= 0.6.0) but 0.6.0-02 is to be installed</span><br><span class="line">E: Unable to correct problems, you have held broken packages.</span><br></pre></td></tr></table></figure>
<p>可以配置 <code>/etc/apt/preferences.d/k8s.pref</code> 作为临时的解决办法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/apt/preferences.d/k8s.pref</span><br><span class="line">Package: kubernetes-cni</span><br><span class="line">Pin: version 0.6.0-02*</span><br><span class="line">Pin-Priority: 900</span><br></pre></td></tr></table></figure>
</li>
<li><p>k8s的网络配置除了 flannel 之外还有 Calico, Canal, Flannel, Kube-router, Romana, Weave Net等，详细的网络列表可参考<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener">插件页面</a>。</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/10/09/Shell中字符串的切割、拼接、比较、替换/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/09/Shell中字符串的切割、拼接、比较、替换/" itemprop="url">Shell中字符串的切割、拼接、比较、替换</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-09T11:20:35+08:00">
                2018-10-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/服务器/" itemprop="url" rel="index">
                    <span itemprop="name">服务器</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="截取"><a href="#截取" class="headerlink" title="截取"></a>截取</h2><h3 id="shell-截取字符变量的前8位，有方法如下："><a href="#shell-截取字符变量的前8位，有方法如下：" class="headerlink" title="shell 截取字符变量的前8位，有方法如下："></a>shell 截取字符变量的前8位，有方法如下：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">expr substr “$a” 1 8</span><br><span class="line">echo $a|awk ‘&#123;print substr(,1,8)&#125;’</span><br><span class="line">echo $a|cut -c1-8</span><br><span class="line">echo $</span><br><span class="line">expr $a : ‘(.\).*’</span><br><span class="line">echo $a|dd bs=1 count=8 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<h3 id="按指定的字符串截取"><a href="#按指定的字符串截取" class="headerlink" title="按指定的字符串截取"></a>按指定的字符串截取</h3><p>第一种方法:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$&#123;varible##*string&#125; 从左向右截取最后一个string后的字符串</span><br><span class="line"></span><br><span class="line">$&#123;varible#*string&#125;从左向右截取第一个string后的字符串</span><br><span class="line"></span><br><span class="line">$&#123;varible%%string*&#125;从右向左截取最后一个string后的字符串</span><br><span class="line"></span><br><span class="line">$&#123;varible%string*&#125;从右向左截取第一个string后的字符串</span><br><span class="line"></span><br><span class="line">“*”只是一个通配符可以不要</span><br></pre></td></tr></table></figure></p>
<p>例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ MYVAR=foodforthought.jpg</span><br><span class="line">$ echo $&#123;MYVAR##*fo&#125;</span><br><span class="line">rthought.jpg</span><br><span class="line">$ echo $&#123;MYVAR#*fo&#125;</span><br><span class="line">odforthought.jpg</span><br></pre></td></tr></table></figure></p>
<p>第二种方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;varible:n1:n2&#125;:截取变量varible从n1到n2之间的字符串</span><br></pre></td></tr></table></figure></p>
<p>可以根据特定字符偏移和长度，使用另一种形式的变量扩展，来选择特定子字符串。试着在 bash 中输入以下行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ EXCLAIM=cowabunga</span><br><span class="line">$ echo $&#123;EXCLAIM:0:3&#125;</span><br><span class="line">cow</span><br><span class="line">$ echo $&#123;EXCLAIM:3:7&#125;</span><br><span class="line">abunga</span><br></pre></td></tr></table></figure>
<p>这种形式的字符串截断非常简便，只需用冒号分开来指定起始字符和子字符串长度。</p>
<p>第三种方法：<br>按照指定要求分割：<br>比如获取后缀名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -al | cut -d “.” -f2</span><br></pre></td></tr></table></figure>
<h2 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h2><h3 id="拼接字符"><a href="#拼接字符" class="headerlink" title="拼接字符"></a>拼接字符</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$value1=home</span><br><span class="line">$value2=$&#123;value1&#125;&quot;=&quot;</span><br><span class="line">echo $value2</span><br></pre></td></tr></table></figure>
<h3 id="拼接字符串"><a href="#拼接字符串" class="headerlink" title="拼接字符串"></a>拼接字符串</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost sh]# var1=/etc/</span><br><span class="line">[root@localhost sh]# var2=yum.repos.d/</span><br><span class="line">[root@localhost sh]# var3=$&#123;var1&#125;$&#123;var2&#125;</span><br><span class="line">[root@localhost sh]# echo $var3</span><br><span class="line">/etc/yum.repos.d/</span><br></pre></td></tr></table></figure>
<h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h2><p>替换命令：<code>${变量/查找/替换值}  一个&#39;/&#39;表示替换第一个&#39;//&#39;表示替换所有，当查找出中出现了：&quot;/&quot;需要转移成&quot;\/&quot;</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[chengmo@localhost ~]$ test=&apos;c:/windows/boot.ini&apos;</span><br><span class="line">[chengmo@localhost ~]$ echo $&#123;test/\//\\&#125;</span><br><span class="line">c:\windows/boot.ini</span><br><span class="line">[chengmo@localhost ~]$ echo $&#123;test//\//\\&#125;</span><br><span class="line">c:\windows\boot.ini</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/09/17/Linux-基础：如何在Ubuntu上检查一个软件包是否安装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/17/Linux-基础：如何在Ubuntu上检查一个软件包是否安装/" itemprop="url">Linux 基础：如何在Ubuntu上检查一个软件包是否安装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-17T23:06:16+08:00">
                2018-09-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/服务器/" itemprop="url" rel="index">
                    <span itemprop="name">服务器</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>如果你正在管理Debian或者Ubuntu服务器，你也许会经常使用dpkg 或者 apt-get命令。这两个命令用来安装、卸载和更新包。</p>
<p>在本篇中，让我们看下如何在基于DEB的系统下检查是否安装了一个包。</p>
<p>要检查特定的包，比如firefox是否安装了，使用这个命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -s firefox</span><br></pre></td></tr></table></figure></p>
<p>示例输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Package: firefox</span><br><span class="line">Status: install ok installed</span><br><span class="line">Priority: optional</span><br><span class="line">Section: web</span><br><span class="line">Installed-Size: 93339</span><br><span class="line">Maintainer: Ubuntu Mozilla Team &lt;ubuntu-mozillateam@lists.ubuntu.com&gt;</span><br><span class="line">Architecture: amd64</span><br><span class="line">Version: 35.0+build3-0ubuntu0.14.04.2</span><br><span class="line">Replaces: kubuntu-firefox-installer</span><br><span class="line">Provides: gnome-www-browser, iceweasel, www-browser</span><br><span class="line">Depends: lsb-release, libasound2 (&gt;= 1.0.16), libatk1.0-0 (&gt;= 1.12.4), libc6 (&gt;= 2.17), libcairo2 (&gt;= 1.2.4), libdbus-1-3 (&gt;= 1.0.2), libdbus-glib-1-2 (&gt;= 0.78), libfontconfig1 (&gt;= 2.9.0), libfreetype6 (&gt;= 2.2.1), libgcc1 (&gt;= 1:4.1.1), libgdk-pixbuf2.0-0 (&gt;= 2.22.0), libglib2.0-0 (&gt;= 2.37.3), libgtk2.0-0 (&gt;= 2.24.0), libpango-1.0-0 (&gt;= 1.22.0), libpangocairo-1.0-0 (&gt;= 1.14.0), libstartup-notification0 (&gt;= 0.8), libstdc++6 (&gt;= 4.6), libx11-6, libxcomposite1 (&gt;= 1:0.3-1), libxdamage1 (&gt;= 1:1.1), libxext6, libxfixes3, libxrender1, libxt6</span><br><span class="line">Recommends: xul-ext-ubufox, libcanberra0, libdbusmenu-glib4, libdbusmenu-gtk4</span><br><span class="line">Suggests: ttf-lyx</span><br><span class="line">Conffiles:</span><br><span class="line">/etc/firefox/syspref.js 09e457e65435a1a043521f2bd19cd2a1</span><br><span class="line">/etc/apport/blacklist.d/firefox ee63264f847e671832d42255912ce144</span><br><span class="line">/etc/apport/native-origins.d/firefox 7c26b75c7c2b715c89cc6d85338252a4</span><br><span class="line">/etc/apparmor.d/usr.bin.firefox f54f7a43361c7ecfa3874abca2f292cf</span><br><span class="line">Description: Safe and easy web browser from Mozilla</span><br><span class="line">Firefox delivers safe, easy web browsing. A familiar user interface,</span><br><span class="line">enhanced security features including protection from online identity theft,</span><br><span class="line">and integrated search let you get the most out of the web.</span><br><span class="line">Xul-Appid: &#123;ec8030f7-c20a-464f-9b0e-13a3a9e97384&#125;</span><br></pre></td></tr></table></figure></p>
<p>如上所见，firefox已经安装了。</p>
<p>同样，你可以使用dpkg-query 命令。这个命令会有一个更好的输出，当然，你可以用通配符。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg-query -l firefox</span><br></pre></td></tr></table></figure>
<p>示例输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Desired=Unknown/Install/Remove/Purge/Hold</span><br><span class="line">| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend</span><br><span class="line">|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)</span><br><span class="line">||/ Name                                 Version                 Architecture            Description</span><br><span class="line">+++-====================================-=======================-=======================-=============================================================================</span><br><span class="line">ii  firefox                              35.0+build3-0ubuntu0.14 amd64                   Safe and easy web browser from Mozilla</span><br></pre></td></tr></table></figure></p>
<p>要列出你系统中安装的所有包，输入下面的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg --get-selections</span><br></pre></td></tr></table></figure></p>
<p>示例输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">abiword                        install</span><br><span class="line">abiword-common                    install</span><br><span class="line">accountsservice                    install</span><br><span class="line">acl                        install</span><br><span class="line">adduser                        install</span><br><span class="line">alsa-base                    install</span><br><span class="line">alsa-utils                    install</span><br><span class="line">anacron                        install</span><br><span class="line">app-install-data                install</span><br><span class="line">apparmor                    install</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">zeitgeist                    install</span><br><span class="line">zeitgeist-core                    install</span><br><span class="line">zeitgeist-datahub                install</span><br><span class="line">zenity                        install</span><br><span class="line">zenity-common                    install</span><br><span class="line">zip                        install</span><br><span class="line">zlib1g:amd64                    install</span><br><span class="line">zlib1g:i386                    install</span><br></pre></td></tr></table></figure></p>
<p>上面的输出可能会非常长，这依赖于你的系统已安装的包。</p>
<p>你同样可以通过grep来过滤割到更精确的包。比如，我想要使用dpkg命令查看系统中安装的gcc包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg --get-selections | grep gcc</span><br></pre></td></tr></table></figure>
<p>示例输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">gcc                        install</span><br><span class="line">gcc-4.8                        install</span><br><span class="line">gcc-4.8-base:amd64                install</span><br><span class="line">gcc-4.8-base:i386                install</span><br><span class="line">gcc-4.9-base:amd64                install</span><br><span class="line">gcc-4.9-base:i386                install</span><br><span class="line">libgcc-4.8-dev:amd64                install</span><br><span class="line">libgcc1:amd64                    install</span><br><span class="line">libgcc1:i386                    install</span><br></pre></td></tr></table></figure></p>
<p>此外，你可以使用“-L”参数来找出包中文件的位置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -L gcc-4.8</span><br></pre></td></tr></table></figure>
<p>示例输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/.</span><br><span class="line">/usr</span><br><span class="line">/usr/share</span><br><span class="line">/usr/share/doc</span><br><span class="line">/usr/share/doc/gcc-4.8-base</span><br><span class="line">/usr/share/doc/gcc-4.8-base/README.Bugs</span><br><span class="line">/usr/share/doc/gcc-4.8-base/NEWS.html</span><br><span class="line">/usr/share/doc/gcc-4.8-base/quadmath</span><br><span class="line">/usr/share/doc/gcc-4.8-base/quadmath/changelog.gz</span><br><span class="line">/usr/share/doc/gcc-4.8-base/gcc</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">/usr/bin/x86_64-linux-gnu-gcc-4.8</span><br><span class="line">/usr/bin/x86_64-linux-gnu-gcc-ar-4.8</span><br><span class="line">/usr/bin/x86_64-linux-gnu-gcov-4.8</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/09/14/Docker-空间使用分析与清理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/14/Docker-空间使用分析与清理/" itemprop="url">Docker 空间使用分析与清理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-14T17:04:45+08:00">
                2018-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/docker/" itemprop="url" rel="index">
                    <span itemprop="name">docker</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>用户在使用 Docker 部署业务一段时间后，可能会发现宿主节点的磁盘容量持续增长，甚至将磁盘空间耗尽进而引发宿主机异常，进而对业务造成影响。 本文先对 Docker 的空间分析与清理进行说明，然后对容器的磁盘容量限制与使用建议做简要说明。</p>
<h1 id="典型问题场景"><a href="#典型问题场景" class="headerlink" title="典型问题场景"></a>典型问题场景</h1><p>用户发现 Docker 宿主机的磁盘空间使用率非常高。通过 du 逐层分析，发现是 Volume 或 overlay2 等目录占用了过高空间。示例如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 根据使用的存储驱动的不同，相应目录会有所不同：</span><br><span class="line">[root@node3 docker]# du -h --max-depth=1 |sort</span><br><span class="line">104K    ./network</span><br><span class="line">13M    ./image</span><br><span class="line">20K    ./plugins</span><br><span class="line">24G    ./overlay2   # 这个目录占用了非常高的磁盘磁盘空间</span><br><span class="line">25G    .</span><br><span class="line">283M    ./volumes</span><br><span class="line">4.0K    ./swarm</span><br><span class="line">4.0K    ./tmp</span><br><span class="line">4.0K    ./trust</span><br><span class="line">518M    ./containers</span><br></pre></td></tr></table></figure>
<h1 id="空间使用分析"><a href="#空间使用分析" class="headerlink" title="空间使用分析"></a>空间使用分析</h1><p>遇到此类问题，可以参阅如下步骤进行空间分析，定位占用过高空间的业务来源。</p>
<h2 id="分析-Docker-空间分布"><a href="#分析-Docker-空间分布" class="headerlink" title="分析 Docker 空间分布"></a>分析 Docker 空间分布</h2><p>Docker 的内置 CLI 指令 docker system df ，可用于查询镜像（Images）、容器（Containers）和本地卷（Local Volumes）等空间使用大户的空间占用情况。 示例输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 docker]# docker system df</span><br><span class="line">TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE</span><br><span class="line">Images              17                  12                  2.713 GB            1.144 GB (42%)</span><br><span class="line">Containers          15                  12                  10.75 GB            0 B (0%)</span><br><span class="line">Local Volumes       8                   4                   282.9 MB            241.8 MB (85%)</span><br></pre></td></tr></table></figure>
<h2 id="查看空间占用细节"><a href="#查看空间占用细节" class="headerlink" title="查看空间占用细节"></a>查看空间占用细节</h2><p>可以进一步通过 -v 参数查看空间占用细节，以确定具体是哪个镜像、容器或本地卷占用了过高空间。示例输出如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 docker]# docker system df -v</span><br><span class="line"># 镜像的空间使用情况</span><br><span class="line">Images space usage:</span><br><span class="line"></span><br><span class="line">REPOSITORY                                                   TAG                 IMAGE ID            CREATED             SIZE                SHARED SIZE         UNIQUE SIZE         CONTAINERS</span><br><span class="line">busybox                                                      latest              6ad733544a63        5 days ago          1.129 MB            0 B                 1.129 MB            1</span><br><span class="line">nginx                                                        latest              b8efb18f159b        3 months ago        107.5 MB            107.5 MB            0 B                 4</span><br><span class="line">ubuntu                                                       latest              14f60031763d        3 months ago        119.5 MB            0 B                 119.5 MB            0</span><br><span class="line">alpine                                                       3.3                 606fed0878ec        4 months ago        4.809 MB            0 B                 4.809 MB            0</span><br><span class="line">tutum/curl                                                   latest              01176385d84a        3 years ago         224.4 MB            0 B                 224.4 MB            1</span><br><span class="line"></span><br><span class="line"># 容器的空间使用情况</span><br><span class="line">Containers space usage:</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE                                                                    COMMAND                  LOCAL VOLUMES       SIZE                CREATED             STATUS                     NAMES</span><br><span class="line">d1da451ceeab        busybox                                                                  &quot;ping 127.0.0.1&quot;         0                   10.7 GB             About an hour ago   Up About an hour           dstest</span><br><span class="line">956ae1d241e8        nginx:latest                                                             &quot;nginx -g &apos;daemon ...&quot;   0                   26 B                3 months ago        Up 3 months                localTest_restserver_2</span><br><span class="line">74973d237a06        nginx:latest                                                             &quot;nginx -g &apos;daemon ...&quot;   0                   2 B                 3 months ago        Up 3 months                </span><br><span class="line"></span><br><span class="line"># 本地卷的空间使用情况</span><br><span class="line">Local Volumes space usage:</span><br><span class="line"></span><br><span class="line">VOLUME NAME                                                        LINKS               SIZE</span><br><span class="line">83ba8747f4172a3c02a15f85b71e1565affca59f01352b4a94e0d28e65c26d1c   0                   830 B</span><br><span class="line">a479c303b278f1442f66644f694a554aac630e72b7a27065a11ef85c4d87b648   0                   22.16 MB</span><br><span class="line">79a25b6376e0d6587d8f4f24e08f9467981f04daad14bf3353a12d727d065503   1                   18.83 MB</span><br></pre></td></tr></table></figure></p>
<h1 id="空间清理"><a href="#空间清理" class="headerlink" title="空间清理"></a>空间清理</h1><h2 id="自动清理"><a href="#自动清理" class="headerlink" title="自动清理"></a>自动清理</h2><p>可以通过 Docker 内置的 CLI 指令 docker system prune 来进行自动空间清理。</p>
<blockquote>
<p>  <strong>Tips</strong> ：</p>
<p>  <strong>不同状态的镜像</strong></p>
<p>  已使用镜像（used image）： 指所有已被容器（包括已停止的）关联的镜像。即 docker ps -a 看到的所有容器使用的镜像。</p>
<p>  未引用镜像（unreferenced image）：没有被分配或使用在容器中的镜像，但它有 Tag 信息。</p>
<p>  悬空镜像（dangling image）：未配置任何 Tag （也就无法被引用）的镜像，所以悬空。这通常是由于镜像 build 的时候没有指定 -t 参数配置 Tag 导致的。比如:<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;   REPOSITORY                                                   TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">&gt;   &lt;none&gt;                                                      &lt;none&gt;              6ad733544a63        5 days ago          1.13 MB   # 悬空镜像（dangling image）</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>  <strong>挂起的卷（dangling Volume)</strong></p>
<p>  类似的，dangling=true 的 Volume 表示没有被任何容器引用的卷。</p>
</blockquote>
<h3 id="docker-system-prune-自动清理说明："><a href="#docker-system-prune-自动清理说明：" class="headerlink" title="docker system prune 自动清理说明："></a>docker system prune 自动清理说明：</h3><ul>
<li><p>该指令默认会清除所有如下资源：</p>
<ul>
<li>已停止的容器（container）</li>
<li>未被任何容器所使用的卷（volume）</li>
<li>未被任何容器所关联的网络（network）</li>
<li>所有悬空镜像（image）。</li>
</ul>
</li>
<li><p>该指令默认只会清除悬空镜像，未被使用的镜像不会被删除。</p>
</li>
<li>添加 -a 或 –all 参数后，可以一并清除所有未使用的镜像和悬空镜像。</li>
<li>可以添加 -f 或 –force 参数用以忽略相关告警确认信息。</li>
<li>指令结尾处会显示总计清理释放的空间大小。</li>
</ul>
<p>操作示例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@node3 docker]# docker system prune --help</span><br><span class="line"></span><br><span class="line">Usage:    docker system prune [OPTIONS]</span><br><span class="line"></span><br><span class="line">Remove unused data</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -a, --all     Remove all unused images not just dangling ones</span><br><span class="line">  -f, --force   Do not prompt for confirmation</span><br><span class="line">      --help    Print usage</span><br><span class="line">[root@node3 docker]# docker system prune -a</span><br><span class="line">WARNING! This will remove:</span><br><span class="line">    - all stopped containers</span><br><span class="line">    - all volumes not used by at least one container</span><br><span class="line">    - all networks not used by at least one container</span><br><span class="line">    - all images without at least one container associated to them</span><br><span class="line">Are you sure you want to continue? [y/N] y</span><br><span class="line">Deleted Containers:</span><br><span class="line">c09c31c49491ee7f2324160e43947917940221b4e6cc1274906def640a7a631f</span><br><span class="line">2aa0180e1a0f4c2c64349a6ed969651052373e7a9471050dce9015701cf1b957</span><br><span class="line">6d18003b06823c5d76d807a319387b06680fc93d0a32bc29c1cea4c07e8d515d</span><br><span class="line"></span><br><span class="line">Deleted Volumes:</span><br><span class="line">a479c303b278f1442f66644f694a554aac630e72b7a27065a11ef85c4d87b648</span><br><span class="line">79a25b6376e0d6587d8f4f24e08f9467981f04daad14bf3353a12d727d065503</span><br><span class="line"></span><br><span class="line">Deleted Images:</span><br><span class="line">untagged: tutum/curl:latest</span><br><span class="line">untagged: tutum/curl@sha256:b6f16e88387acd4e6326176b212b3dae63f5b2134e69560d0b0673cfb0fb976f</span><br><span class="line">deleted: sha256:01176385d84aeb1d40ed18c6d3f952abf40d2d2b4aa98fcf0a8a4b01010fb9a9</span><br><span class="line">deleted: sha256:c84f85637212412c1d46d1dd50f789df2c3b44678ee3fee6a820888e734f9b5a</span><br><span class="line">untagged: test:lastest</span><br><span class="line">deleted: sha256:794ff09332586a091514eb3d1c44990244e57e34adc71d4b4334c0674a1377e9</span><br><span class="line">deleted: sha256:636a1e7769d2242556243e9a21fb96bb878ab5b94c41ff485667252c968b375e</span><br><span class="line"></span><br><span class="line">Total reclaimed space: 1.565 GB</span><br></pre></td></tr></table></figure>
<h2 id="手动清理"><a href="#手动清理" class="headerlink" title="手动清理"></a>手动清理</h2><h3 id="网络清理"><a href="#网络清理" class="headerlink" title="网络清理"></a>网络清理</h3><p>网络配置通常占用的空间非常低，略过。</p>
<h3 id="镜像清理"><a href="#镜像清理" class="headerlink" title="镜像清理"></a>镜像清理</h3><p>如果通过 docker system df 分析，是镜像占用了过高空间。则可以根据业务情况，评估相关镜像的使用情况。对于悬空和未使用的镜像， 可以使用如下指令手工清理：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 删除所有悬空镜像，但不会删除未使用镜像：</span><br><span class="line">docker rmi $(docker images -f "dangling=true" -q)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 删除所有未使用镜像和悬空镜像。</span><br><span class="line"><span class="meta">#</span> 【说明】：轮询到还在被使用的镜像时，会有类似"image is being used by xxx container"的告警信息，所以相关镜像不会被删除，忽略即可。</span><br><span class="line">docker rmi $(docker images-q)</span><br></pre></td></tr></table></figure>
<h3 id="卷清理"><a href="#卷清理" class="headerlink" title="卷清理"></a>卷清理</h3><p>如果通过 docker system df 分析，是卷占用了过高空间。则可以根据业务情况，评估相关卷的使用情况。对于未被任何容器调用的卷（-v 结果信息中，”LINKS” 显示为 0），可以使用如下指令手工清理：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 删除所有未被任何容器关联引用的卷：</span><br><span class="line">docker volume rm $(docker volume ls -qf dangling=true)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 也可以直接使用如下指令，删除所有未被任何容器关联引用的卷（但建议使用上面的方式）</span><br><span class="line"><span class="meta">#</span> 【说明】轮询到还在使用的卷时，会有类似"volume is in use"的告警信息，所以相关卷不会被删除，忽略即可。</span><br><span class="line">docker volume rm $(docker volume ls -q)</span><br></pre></td></tr></table></figure>
<h3 id="容器清理"><a href="#容器清理" class="headerlink" title="容器清理"></a>容器清理</h3><p>如果通过 docker system df 分析，是某个容器占用了过高空间。则可以根据业务情况，评估相关容器的业务归属并进行处理。对于已停止或其它异常状态的容器，可以结合  -f 或 –filter 筛选器，使用类似如下指令来手工清理：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 删除所有已退出的容器</span><br><span class="line">docker rm -v $(docker ps -aq -f status=exited)</span><br><span class="line"><span class="meta">#</span> 删除所有状态为 dead 的容器</span><br><span class="line">docker rm -v $(docker ps -aq -f status=dead)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>更多关于 ps 指令支持的筛选器信息，可以参阅<a href="https://docs.docker-cn.com/engine/reference/commandline/ps/#filtering" target="_blank" rel="noopener">官方文档</a>。</p>
</blockquote>
<h1 id="在用空间资源分析"><a href="#在用空间资源分析" class="headerlink" title="在用空间资源分析"></a>在用空间资源分析</h1><p>对于还在使用的空间资源，可以参阅如下说明做进一步排查分析。</p>
<h2 id="镜像空间分析"><a href="#镜像空间分析" class="headerlink" title="镜像空间分析"></a>镜像空间分析</h2><p>如果某个镜像占用了过高空间，则可以通过如下方式做进一步空间分析：</p>
<ol>
<li>通过 docker system df 获取占用过高空间的镜像信息。</li>
<li>基于相应镜像创建测试容器。</li>
<li>exec 进入容器后，结合 du 等 shell 指令做进一步空间分析，定位出占用最高空间的目录或文件。</li>
<li>结合业务情况做进一步处理，重新 build 镜像。</li>
</ol>
<p>示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@node3]# docker exec -it dstest sh</span><br><span class="line">/ # du -h | head</span><br><span class="line">8.0K    ./root</span><br><span class="line">32.0K    ./etc</span><br><span class="line">4.0K    ./usr/sbin</span><br><span class="line">8.0K    ./usr</span><br><span class="line">10.0G    ./home/java/logs</span><br><span class="line">10.0G    ./home/java</span><br><span class="line">10.0G    ./home</span><br><span class="line">1.1M    ./bin</span><br><span class="line">0    ./dev/shm</span><br><span class="line">0    ./dev/mqueue</span><br></pre></td></tr></table></figure></p>
<h2 id="容器空间分析"><a href="#容器空间分析" class="headerlink" title="容器空间分析"></a>容器空间分析</h2><p>如果某个运行中的容器占用了过高空间，则可以通过如下方式做进一步空间分析：</p>
<blockquote>
<p>  <strong>Tips</strong> ：</p>
<p>  <strong>容器的只读层与镜像层的空间占用情况</strong></p>
<p>  一个容器的占用的总空间，包含其最顶层的读写层（writable layer）和底部的只读镜像层（base image layer，read-only）。更多相关说明，可以参阅<a href="https://docs.docker-cn.com/engine/userguide/storagedriver/imagesandcontainers/?spm=a2c4e.11153940.blogcont272173.14.4a6d22130uX2V6#container-and-layers" target="_blank" rel="noopener">官方文档</a>。</p>
<p>  可以通过 docker ps 的 -s 参数来分别显示二者的空间占用情况，进而判断相应容器的空间占用主要是来自原始镜像，还是运行中产生。</p>
<p>  <img src="../images/82ce6b220fe5aef04c051db37c20460d.png" alt=""></p>
<p>  示例<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&gt;   # 如下容器的原始镜像占用了 422MB 空间，实际运行过程中只占用了 2B 空间：</span><br><span class="line">&gt;   CONTAINER ID    IMAGE                                           COMMAND                 CREATED         STATUS      PORTS                   NAMES       SIZE</span><br><span class="line">&gt;   ac39128ccbc0    registry.aliyuncs.com/acs-sample/wordpress:4.6  &quot;/entrypoint.sh ap...&quot;  3 months ago    Up 11 days  0.0.0.0:32779-&gt;80/tcp   Web_web_4   2 B (virtual 422 MB)</span><br><span class="line"></span><br><span class="line">## 容器空间占用的分析步骤：</span><br><span class="line"></span><br><span class="line">1.  通过 docker system df 获取占用过高空间的容器信息。</span><br><span class="line">2.  通过前述 -s 参数确认到底是底层镜像，还是运行过程中产生的数据占用了过高空间。</span><br><span class="line">3.  exec 进入容器，结合 du 等 shell 指令做进一步空间分析，定位出占用最高空间的目录或文件。</span><br><span class="line">4.  结合业务情况做进一步处理。</span><br><span class="line"></span><br><span class="line"># 引申：Docker 磁盘空间限制与使用建议</span><br><span class="line"></span><br><span class="line">## 磁盘空间限制</span><br><span class="line"></span><br><span class="line">### 使用 Device Mapper 存储驱动限制容器磁盘空间</span><br><span class="line"></span><br><span class="line">如果使用 Device Mapper 作为底层存储驱动，则可以通过 Docker daemon 的如下参数来全局限制单个容器占用空间的大小：</span><br><span class="line"></span><br><span class="line">+ --storage-opt dm.basesize=20G 表示限制单个容器最多占用 20G 空间，将应用于任何新建容器。</span><br><span class="line"></span><br><span class="line">更多关于 Device Mapper 存储驱动的说明，可以参阅[官方文档](https://docs.docker-cn.com/engine/userguide/storagedriver/device-mapper-driver/)。</span><br><span class="line"></span><br><span class="line">### 使用 btrfs 存储驱动限制容器磁盘空间</span><br><span class="line"></span><br><span class="line">btrfs 驱动主要使用 btrfs 所提供的 subvolume 功能来实现。一个容器会对应一个 subvolume。针对容器对应的 subvolume 启用并配置 quota 即可限制其磁盘空间。示例配置：</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>btrfs qgroup limit -e 50G /var/lib/docker/btrfs/subvolumes/&lt;CONTAINER_ID&gt;<br><code>`</code><br>btrfs 还有其它很好的特性，比如可以在线扩容（在线加入一块新的块设备，来扩充整个文件系统的大小）。更多关于 btrfs 存储驱动的说明，可以参阅<a href="https://docs.docker-cn.com/engine/userguide/storagedriver/btrfs-driver/" target="_blank" rel="noopener">官方文档</a>。</p>
<h3 id="外挂-LVM-卷"><a href="#外挂-LVM-卷" class="headerlink" title="外挂 LVM 卷"></a>外挂 LVM 卷</h3><p>如果使用的是其它不支持对单个容器的磁盘容量进行限制的存储驱动，则可以考虑如下通用方案：</p>
<ul>
<li>通过 LVM 方式创建一个指定容量的卷,然后挂载到宿主操作系统上特定目录。最后通过 –volume 参数来让容器来挂载使用相应目录。</li>
</ul>
<p><strong>注意</strong>：该方案的前提条件是，容器中所有落盘操作要全部落到上述 “–volume” 参数指定的卷中，否则容器还会占用默认 aufs 所在盘的空间,进而造成统计不准。</p>
<h3 id="Docker-存储使用建议"><a href="#Docker-存储使用建议" class="headerlink" title="Docker 存储使用建议"></a>Docker 存储使用建议</h3><p>细化的存储使用最佳实践与采用的存储驱动（storage driver）类型强相关，您可以参阅官方文档做相关了解，本文不做进一步细化说明。</p>
<p>通用的存储使用建议如下：</p>
<ul>
<li>容器内的业务日志务必配置轮询覆写，或者使用日志驱动将日志输出到外部存储。避免日志文件持续增长，占用过高磁盘空间。</li>
<li>结合外部监控对宿主机的磁盘空间使用情况进行监控和告警。</li>
<li>可以参阅文档 <a href="https://yq.aliyun.com/articles/53313?spm=a2c4e.11153940.blogcont272173.18.4a6d2213tOtBnG" target="_blank" rel="noopener">如何给容器服务的Docker增加数据盘</a>来扩容默认 Docker 存储空间。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/09/13/linux命令之-sed命令用于处理文本文件如修改配置文件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/13/linux命令之-sed命令用于处理文本文件如修改配置文件/" itemprop="url">linux命令之 sed命令用于处理文本文件如修改配置文件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-13T10:51:31+08:00">
                2018-09-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/服务器/" itemprop="url" rel="index">
                    <span itemprop="name">服务器</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1、sed命令作用"><a href="#1、sed命令作用" class="headerlink" title="1、sed命令作用"></a>1、sed命令作用</h1><p>Linux sed命令是利用script来处理文本文件。</p>
<p>sed可依照script的指令，来处理、编辑文本文件。</p>
<p>Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。</p>
<h1 id="2、sed语法"><a href="#2、sed语法" class="headerlink" title="2、sed语法"></a>2、sed语法</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件]</span><br></pre></td></tr></table></figure>
<h2 id="常用选项："><a href="#常用选项：" class="headerlink" title="常用选项："></a>常用选项：</h2><ul>
<li>-n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。</li>
<li>-e∶直接在指令列模式上进行 sed 的动作编辑；</li>
<li>-f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作；</li>
<li>-r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法)</li>
<li>-i∶直接修改读取的档案内容，而不是由萤幕输出。       </li>
</ul>
<h2 id="常用命令："><a href="#常用命令：" class="headerlink" title="常用命令："></a>常用命令：</h2><ul>
<li>a   ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～</li>
<li>c   ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！</li>
<li>d   ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚；</li>
<li>i   ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；</li>
<li>p  ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～</li>
<li>s  ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！</li>
</ul>
<h1 id="3、sed案例"><a href="#3、sed案例" class="headerlink" title="3、sed案例"></a>3、sed案例</h1><ol>
<li><p>删除某行</p>
<p> 删除第一行: <code>sed &#39;1d&#39;  a.txt</code></p>
<p> 删除最后一行: <code>sed &#39;$d&#39; a.txt</code></p>
<p> 删除第一行到第二行: <code>sed &#39;1,2d&#39; a.txt</code></p>
</li>
<li><p>增加一行或多行字符串</p>
<p> 第一行到第三行后增加字符串”drink tea”: <code>sed &#39;1,3a drink tea&#39; a.txt</code></p>
</li>
<li><p>代替一行或多行</p>
<p> 第一行到第二行代替为Hi: <code>sed &#39;1,2c Hi&#39; ab</code></p>
</li>
<li><p>数据的搜寻并替换</p>
<p> sed ‘s/要被取代的字串/新的字串/g’</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">root@sdap#</span><span class="bash"> /bin/ifconfig eth0 | grep <span class="string">'inet addr'</span> | sed <span class="string">'s/^.*addr://g'</span> 只显示inet addr 一行，并且将 IP 前面的部分予以删除显示</span></span><br><span class="line">192.168.0.22  Bcast:192.1680.255  Mask:255.255.255.</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据的搜寻并执行命令<br> 搜索/etc/passwd,找到root对应的行，执行后面花括号中的一组命令，每个命令之间用分号分隔，这里把bash替换为blueshell，再输出这行</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nl /etc/passwd | sed -n '/root/&#123;s/bash/blueshell/;p&#125;'</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="4、脚本案例"><a href="#4、脚本案例" class="headerlink" title="4、脚本案例"></a>4、脚本案例</h1><p>判断目录是否正确并修改配置文件的字段属性<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">CurDir=`pwd`</span><br><span class="line"></span><br><span class="line">A="console"</span><br><span class="line">B="analysis"</span><br><span class="line">displayIP="192.168.2.11" </span><br><span class="line">analysisIP="192.168.2.13"</span><br><span class="line">echo "----Please  check that the following information is correct!-----"</span><br><span class="line">echo "Dispalyip:$displayIP"</span><br><span class="line">echo "analysisIP:$analysisIP" </span><br><span class="line"><span class="meta">#</span><span class="bash">console  </span></span><br><span class="line">if [[ $CurDir =~ $display ]]</span><br><span class="line">then</span><br><span class="line">    sed -i "s/&lt;smap ip=\".*/&lt;smap ip=\"$displayIP\" port=\"10000\" version=\"V3\"\&gt;/g" ../sysfile/config.xml</span><br><span class="line">elif [[ $CurDir =~ $alarm ]]</span><br><span class="line">then</span><br><span class="line">    sed -i "s/&lt;smap ip=\".*/&lt;smap ip=\"$displayIP\" port=\"10000\" version=\"V3\"\&gt;/g" ../sysfile/config.xml</span><br><span class="line">else</span><br><span class="line">    echo "无需要配置的文件！"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zhanghongtong.github.io/2018/09/13/Linux下-shell获取本机ip地址/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张奇怪">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="张奇怪的blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/13/Linux下-shell获取本机ip地址/" itemprop="url">Linux下 shell获取本机ip地址</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-13T10:30:17+08:00">
                2018-09-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/服务器/" itemprop="url" rel="index">
                    <span itemprop="name">服务器</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>获取所有的网卡地址<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sbin/ifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6 | awk &apos;&#123;print $2&#125;&apos; | tr -d &quot;addr:&quot;</span><br></pre></td></tr></table></figure></p>
<p>假设网卡名为 <code>eth0</code> , 获取本机ip地址地址，并保存到变量中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arg=ifconfig eth0 |grep &quot;inet addr&quot;| cut -f 2 -d &quot;:&quot;|cut -f 1 -d &quot; &quot; </span><br><span class="line">ipaddr=$arg</span><br><span class="line"></span><br><span class="line">echo $ipadd</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="张奇怪" />
          <p class="site-author-name" itemprop="name">张奇怪</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张奇怪</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  

</body>
</html>
